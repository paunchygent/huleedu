---
id: "070.1-performance-testing-methodology"
type: "testing"
created: 2025-08-03
last_updated: 2025-11-17
scope: "backend"
parent_rule: "070-testing-and-quality-assurance"
---

# 070.1: Performance Testing Patterns

## 1. Testing Strategy Matrix

| Test Type         | Infrastructure | LLM Provider | Purpose                    | Example Use Case |
|------------------|----------------|--------------|----------------------------|------------------|
| Unit Tests       | Mock          | Mock         | Fast feedback             | Business logic validation |
| Integration      | Real          | Mock         | Infrastructure validation | Database/Queue performance |
| Performance      | Real          | Mock         | Meaningful metrics        | Redis pipeline benchmarks |
| E2E             | Real          | Real         | Full system validation    | End-to-end workflows |
| Outbox Testing   | Real (testcontainers) | Mock | Event reliability | Outbox + relay worker |

## 2. Infrastructure vs Mock Testing

### 2.1. Real Infrastructure Testing
- **WHEN**: Testing infrastructure performance, reliability, resource usage
- **COMPONENTS**: Use real Redis, Kafka, PostgreSQL via testcontainers
- **BENEFITS**: Realistic performance metrics, actual network latency, real resource consumption

### 2.2. Mock LLM Provider Testing
- **WHEN**: Performance testing that needs meaningful data without API costs
- **IMPLEMENTATION**: Use `MockProviderImpl` with `performance_mode=True`
- **PATTERN**: Mock errors disabled in performance mode for consistent results

## 3. Performance Testing Patterns

### 3.1. Testcontainer Configuration
```python
@pytest.fixture(scope="class")
def redis_container() -> Generator[RedisContainer, None, None]:
    with RedisContainer("redis:7-alpine") as container:
        yield container

@pytest.fixture(scope="class")
def kafka_container() -> Generator[KafkaContainer, None, None]:
    with KafkaContainer("confluentinc/cp-kafka:7.4.0") as container:
        yield container
```

### 3.2. Performance-Optimized Mock Providers
```python
@provide(scope=Scope.APP)
async def provide_llm_provider_map(self, settings: Settings) -> Dict[LLMProviderType, LLMProviderProtocol]:
    mock_provider = MockProviderImpl(
        settings=settings, 
        seed=42, 
        performance_mode=True  # Disables error simulation
    )
    return {
        LLMProviderType.MOCK: mock_provider,
        LLMProviderType.ANTHROPIC: mock_provider,
    }
```

### 3.3. DI Container Cleanup Pattern
```python
@pytest.fixture
async def infrastructure_di_container(settings: Settings) -> AsyncGenerator[Any, None]:
    container = make_async_container(TestProvider(settings))
    
    try:
        yield container
    finally:
        # CRITICAL: Clean up all infrastructure components
        async with container() as request_container:
            for client_type in [QueueRedisClientProtocol, RedisClientProtocol]:
                try:
                    client = await request_container.get(client_type)
                    if hasattr(client, 'stop'):
                        await client.stop()
                except Exception as e:
                    print(f"⚠ Failed to stop {client_type.__name__}: {e}")
```

## 4. Performance Benchmarking Standards

### 4.1. Realistic Performance Targets
- **Redis Operations**: < 0.1s per operation (achieved: 0.3ms)
- **Queue Throughput**: < 0.2s per retrieval  
- **Batch Operations**: < 0.15s per request
- **Concurrent Operations**: < 0.2s average response time
- **E2E Pipeline**: P95 < 5.0s, 90% success rate

### 4.2. Performance Metrics Collection
```python
class PerformanceMetrics:
    def add_measurement(self, response_time: float, status_code: int, error: Optional[str] = None) -> None:
        """Add a performance measurement."""
        
    def get_statistics(self) -> Dict[str, Any]:
        """Get comprehensive performance statistics including P95, P99, error rates."""
```

## 5. Test Isolation and Resource Management

### 5.1. Queue Cleanup Between Tests
```python
@pytest.fixture(autouse=True)
async def clean_redis_queue(redis_container: RedisContainer) -> None:
    client = redis_container.get_client()
    await client.flushdb()
    yield
```

### 5.2. Resource Cleanup Patterns
- **MUST** use `try/finally` blocks for resource cleanup
- **PATTERN**: Print warnings for cleanup failures (don't fail tests)
- **SCOPE**: Use appropriate fixture scopes (`class` for containers, `function` for DI)

## 6. Performance Test Categories

### 6.1. Load Testing
- **Pattern**: Sustained request rates over time
- **Metrics**: Requests per second, P95/P99 response times
- **Example**: 2 req/s for 15 seconds with real infrastructure

### 6.2. Stress Testing  
- **Pattern**: Concurrent operations with varying load
- **Metrics**: Success rates, resource utilization
- **Example**: 25 concurrent Redis operations

### 6.3. Endurance Testing
- **Pattern**: Mixed workload types over extended periods
- **Metrics**: Performance degradation over time
- **Example**: Mixed quick/detailed/batch workloads

## 7. Bulk Operation Testing Patterns

### 7.1. Concurrent Data Generation
```python
class BulkTestDataGenerator:
    @staticmethod
    def generate_unique_requests(count: int) -> List[RequestModel]:
        """Generate requests with UUID suffixes for concurrent safety."""
        unique_suffix = str(uuid.uuid4()).replace('-', '')[:8]
        # Pattern ensures no conflicts across concurrent test execution
```

### 7.2. Bulk Workflow Testing Structure
- **Single Entity Bulk**: Test realistic batch sizes per operation
- **Multi-Entity Workflows**: Multiple related entities in sequence
- **Concurrent Bulk Operations**: Parallel bulk operations across users
- **Constraint Validation**: Database integrity under bulk load
- **Memory Efficiency**: Large batch memory patterns

### 7.3. Bulk Performance Test Architecture
```python
# Bulk performance test structure
tests/performance/
├── conftest.py                    # Bulk operation fixtures
├── test_single_bulk_*.py         # Individual bulk operation patterns  
├── test_concurrent_bulk_*.py     # Concurrent bulk operation patterns
├── test_database_bulk_*.py       # Database bulk operation patterns
```

## 8. Outbox Pattern Testing

### 8.1. Unit Testing Outbox Repository
```python
@pytest.mark.asyncio
async def test_outbox_repository_stores_event():
    outbox_repo = PostgreSQLOutboxRepository(test_engine)
    
    event_id = await outbox_repo.add_event(
        aggregate_id="test-123",
        aggregate_type="test_entity",
        event_type="test.event.v1",
        event_data={"test": "data"},
        topic="test.events",
    )
    
    event = await outbox_repo.get_event_by_id(event_id)
    assert event.aggregate_id == "test-123"
    assert event.published_at is None  # Not yet published
```

### 8.2. Integration Testing with Testcontainers
```python
@pytest.mark.asyncio
async def test_event_relay_worker_publishes_events(
    postgres_container,
    kafka_container,
):
    outbox_repo = PostgreSQLOutboxRepository(postgres_engine)
    kafka_bus = KafkaBus(kafka_container.bootstrap_servers)
    
    worker = EventRelayWorker(
        outbox_repository=outbox_repo,
        kafka_bus=kafka_bus,
        settings=OutboxSettings(poll_interval_seconds=0.1),
        service_name="test_service",
    )
    
    await outbox_repo.add_event(
        aggregate_id="test-123",
        event_data={"topic": "test.events", "data": "test"},
        topic="test.events",
    )
    
    await worker.start()
    await asyncio.sleep(0.2)
    await worker.stop()
    
    events = await outbox_repo.get_unpublished_events()
    assert len(events) == 0  # All events published
```

### 8.3. Business Logic with Outbox Testing
```python
@pytest.mark.asyncio
async def test_business_operation_with_outbox():
    async with test_session.begin() as session:
        result = await repository.update_entity(
            entity_id="test-id",
            updates={"status": "processed"},
            session=session,
        )
        
        await outbox_repository.add_event(
            aggregate_id="test-id",
            event_data={"result": result.model_dump()},
            session=session,
        )
        
        await session.commit()
    
    entity = await repository.get_entity("test-id")
    assert entity.status == "processed"
    
    events = await outbox_repository.get_unpublished_events()
    assert len(events) == 1
    assert events[0].aggregate_id == "test-id"
```
