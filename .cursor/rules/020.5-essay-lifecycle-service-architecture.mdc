---
description: Defines the Essay Lifecycle Service (ELS). Manages individual essay state via a Kafka worker and HTTP API. Uses SQLite for persistence and coordinates with the Batch Orchestrator Service.
globs: 
alwaysApply: false
---
# 020.5: Essay Lifecycle Service Architecture

**STATUS**: ✅ **OPERATIONAL** - Service tested and confirmed working (Jan 2025)
- **Health Endpoint**: `/healthz` returns HTTP 200 with service status
- **Metrics Endpoint**: `/metrics` returns Prometheus metrics with request counters and duration histograms
- **Container**: Running successfully on port 6001 with proper health checks

## 1. Service Identity
- **Package**: `huleedu-essay-lifecycle-service`  
- **HTTP Port**: 6000 (API), **Metrics Port**: 6001
- **Stack**: Quart, aiokafka, aiosqlite, Hypercorn
- **Purpose**: Essay slot assignment, state management, and command processing

## 2. Dual Architecture Pattern

### 2.1. HTTP API (`app.py`)
- **GET /healthz**: Service health
- **GET /metrics**: Prometheus metrics
- **Future**: Essay status queries, manual state transitions

### 2.2. Kafka Worker (`worker_main.py`)  
- **Consumer**: Batch coordination events
- **Producer**: Essay lifecycle state updates
- **Topics**: `huleedu.batch.coordination.*`

## 3. Core Components

### 3.1. Slot Assignment Architecture
- **`batch_tracker.py`**: Slot-based coordination (BOS slots → content assignment)
- **`state_store.py`**: SQLite essay state persistence with slot assignment methods
- **Pattern**: BOS generates slots → ELS assigns content → publishes `BatchEssaysReady`

### 3.2. Command Processing
- **`batch_command_handlers.py`**: BOS command routing and event handlers
- **`implementations/batch_command_handler_impl.py`**: Command processing logic
- **`implementations/service_request_dispatcher.py`**: ELS → specialized service dispatch
- **Pattern**: BOS command → essay state updates → specialized service requests

## 4. Event Integration

### 4.1. Consumed Events
- `BATCH_ESSAYS_REGISTERED`: BOS slot registration
- `ESSAY_CONTENT_PROVISIONED`: File Service content provisioning
- `BATCH_SPELLCHECK_INITIATE_COMMAND`: BOS spellcheck commands

### 4.2. Published Events  
- `BATCH_ESSAYS_READY`: Complete batch readiness notification
- `EXCESS_CONTENT_PROVISIONED`: Content overflow notifications
- `ESSAY_LIFECYCLE_SPELLCHECK_REQUEST`: Spellcheck requests to specialized services

## 5. Configuration

**Environment Variables**:
- `HTTP_PORT` (default: 6000), `METRICS_PORT` (default: 6001)
- `KAFKA_BOOTSTRAP_SERVERS`, `KAFKA_CONSUMER_GROUP_ID`
- `DATABASE_PATH` (default: "essay_lifecycle.db")
- `LOG_LEVEL`, `KAFKA_*` consumer settings

## 6. Database Schema

**SQLite Tables**:
- `processed_essays`: Essay state and metadata
- `batch_uploads`: Batch coordination data  
- `processing_pipeline_states`: Pipeline progress tracking

**Migrations**: Automatic on startup via `state_store.py`

## 7. Dependencies

**Core**: quart, hypercorn, aiokafka, aiosqlite
**HuleEdu**: huleedu-common-core, huleedu-service-libs
**DI**: dishka, quart-dishka

## 8. Deployment

**Docker**: Multi-stage with HTTP API and Kafka worker
**Commands**: `pdm run start-http`, `pdm run start-worker`, `pdm run dev`
**Health**: HTTP healthz endpoint and Kafka consumer health

## 9. Error Handling

**Database**: Connection failures, constraint violations
**Kafka**: Consumer lag, deserialization errors
**State**: Invalid transitions, missing entities
**Response**: Structured error messages with correlation IDs

## 10. Production Implementation Standards

### 10.1. Mandatory Production Patterns
- **MUST** implement graceful shutdown with proper async resource cleanup
- **MUST** use DI-managed `aiohttp.ClientSession` with configured timeouts
- **MUST** use manual Kafka commits with error boundaries (no auto-commit)
- **MUST** implement `/healthz` with consistent JSON response format
- **MUST** fail fast on startup errors with `logger.critical()` and `raise`

## 11. Monitoring

**Metrics**: HTTP requests, Kafka processing, database operations
**Logging**: Correlation ID tracking, state change audit trail
**Health**: Database connectivity, Kafka consumer lag

## 11. Future Evolution

**Planned**: REST API for essay queries, manual state overrides, batch analytics
**Database**: Migration to PostgreSQL for production scalability
**Events**: Fine-grained essay state change events for downstream services
