---
description: Defines the CJ Assessment Service. An integrated Quart application with Kafka consumer performing Comparative Judgement on essays via centralized LLM Provider Service. Includes circuit breaker resilience and comprehensive observability.
alwaysApply automatically when editing files in the cj_assessment_service directory

globs: 
  - "services/cj_assessment_service/**"
alwaysApply: false
---

# 020.7: CJ Assessment Service Architecture

## 1. Service Identity
- **Package**: `huleedu-cj-assessment-service`
- **Folders**: `services/cj_assessment_service/`
- **Ports**: 9095 (HTTP health / metrics), **Kafka**: Consumer/Producer, **DB**: PostgreSQL (port 5434)
- **Stack**: Integrated Quart application, aiokafka, async SQLAlchemy, Dishka DI, OpenTelemetry, Circuit Breakers, Redis
- **Purpose**: Perform Comparative Judgement (CJ) assessments on essay batches using centralized LLM Provider Service, publish rankings/failure events with comprehensive resilience patterns.

## 2. Integrated Application Architecture

### 2.1. Single Entrypoint (`app.py`)
- **HTTP Health API**: GET /healthz (JSON health status), GET /metrics (Prometheus)
- **Kafka Consumer**: Managed via @app.before_serving/@app.after_serving lifecycle hooks
- **Pattern**: Integrated Quart application following Rule 042 HTTP Service Pattern
- **Blueprint Registration**: Single health_bp with shared DI container

### 2.2. Event Processing
- **Consumes**: 
  - `huleedu.els.cj_assessment.requested.v1` (assessment requests)
  - `huleedu.llm_provider.comparison_result.v1` (LLM callbacks)
- **Produces**: `huleedu.cj_assessment.completed.v1`, `huleedu.cj_assessment.failed.v1`
- **Flow**: 
  - Requests: Event → `process_single_message()` → `run_cj_assessment_workflow()` → submit comparisons
  - Callbacks: Event → `process_llm_result()` → `continue_cj_assessment_workflow()` → state updates → publish result

## 3. Core Components

| Module | Responsibility |
| ------ | -------------- |
| `event_processor.py` | Validates envelope, orchestrates workflow, constructs outgoing events, processes callbacks |
| `cj_core_logic/*` | Pair generation, comparison workflow, Bradley-Terry scoring, workflow state management |
| `cj_core_logic/workflow_logic.py` | State machine for callback processing and batch progress tracking |
| `implementations/llm_provider_service_client.py` | HTTP client for LLM Provider Service (event-driven, no polling) |
| `implementations/llm_interaction_impl.py` | Orchestrates concurrent LLM requests via service client |
| `implementations/db_access_impl.py` | Async SQLAlchemy repository (PostgreSQL) |
| `implementations/event_publisher_impl.py` | Kafka publishing abstraction |
| `batch_monitor.py` | Background monitoring for stuck batch detection and recovery |
| `protocols.py` | All **typing.Protocol** contracts (ContentClient, Cache, LLMProvider, Repository, EventPublisher, RetryManager, LLMInteraction) |
| `di.py` | `CJAssessmentServiceProvider` supplying Dishka providers & single `make_async_container` entry |

## 4. Dependency Injection (Dishka)
- DI container instantiated **before** Blueprint registration (see `app.py`) following Memory `55c2a6bd...`.
- **Scope**: `Scope.APP` for all provided components.
- Providers include LLM provider map and optional `MockLLMInteractionImpl` (controlled by `USE_MOCK_LLM`).

## 5. Event Contracts
- **Consumed**: `ELS_CJAssessmentRequestV1` (thin event, payload includes essay refs + overrides).
- **Published**:
  - `CJAssessmentCompletedV1` with rankings list.
  - `CJAssessmentFailedV1` with detailed `error_info`.
- **Envelope**: `EventEnvelope` with **top-level** `schema_version` (see Rule 052).
- **Correlation IDs**: Always `uuid.UUID`; test mocks must expect UUID objects (Memory 234cf4fe...).

## 6. Database Schema & Ranking Strategy (Async SQLAlchemy)
- **Tables**: `cj_batch_uploads`, `cj_processed_essays`, `cj_comparison_pairs`, `cj_batch_states`
- **Key Relationships**: 
  - ELS essay IDs as string primary keys, CASCADE foreign keys
  - One-to-one relationship between `cj_batch_uploads` and `cj_batch_states`
  - Comparison pairs linked to callbacks via `request_correlation_id`
- **State Management**: `CJBatchState` tracks real-time processing progress (INITIALIZING → GENERATING_PAIRS → WAITING_CALLBACKS → SCORING → COMPLETED/FAILED)
- **Ranking Strategy**: Rankings generated dynamically from `ProcessedEssay.current_bt_score` via `get_essay_rankings()`
- **No Persistent Rankings**: Rankings computed on-demand, not stored separately (intentional design)
- **Rationale**: Rankings deterministically derivable from Bradley-Terry scores, avoids data duplication
- **Migration**: Alembic migrations for schema evolution
- **Connection**: `DATABASE_URL_CJ` (SQLite dev, PostgreSQL prod), **Pool Config**: size=10, max_overflow=20, pre_ping=True, recycle=3600

## 7. LLM Interaction Flow (Event-Driven)
1. `pair_generation.py` selects comparison pairs.
2. For each pair a prompt is rendered from `ASSESSMENT_PROMPT_TEMPLATE`.
3. `LLMProviderServiceClient` makes HTTP request with callback topic
   - **200 Response**: Immediate result processed directly
   - **202 Response**: Request queued, result arrives via Kafka callback
4. `LLMInteractionImpl.perform_comparisons()` orchestrates concurrent requests
5. Callbacks arrive on `huleedu.llm_provider.comparison_result.v1` topic
6. `workflow_logic.py` processes callbacks, updates state, checks progress
7. When sufficient comparisons complete, `scoring_ranking.py` calculates final rankings

## 8. Configuration (env vars / Settings)
Key vars from `Settings` (env prefix `CJ_ASSESSMENT_SERVICE_`):
- **Core**: `LOG_LEVEL`, `USE_MOCK_LLM`, `KAFKA_BOOTSTRAP_SERVERS`, `DEFAULT_LLM_PROVIDER`
- **Database**: `DATABASE_URL_CJ`, `DATABASE_POOL_SIZE`, `DATABASE_MAX_OVERFLOW`, `DATABASE_POOL_PRE_PING`, `DATABASE_POOL_RECYCLE`
- **Services**: `CONTENT_SERVICE_URL`, `LLM_PROVIDER_SERVICE_URL`
- **Callback Configuration**: `LLM_PROVIDER_CALLBACK_TOPIC` (default: `huleedu.llm_provider.comparison_result.v1`)
- **Batch Processing**: `BATCH_TIMEOUT_HOURS` (4), `BATCH_MONITOR_INTERVAL_MINUTES` (5), `MIN_SUCCESS_RATE_THRESHOLD` (0.8)
- **Score Stability**: `SCORE_STABILITY_THRESHOLD` (0.05), `MAX_ITERATIONS` (5), `MAX_CONCURRENT_COMPARISONS` (100)
- **Circuit Breaker**: `CIRCUIT_BREAKER_ENABLED`, `*_FAILURE_THRESHOLD`, `*_RECOVERY_TIMEOUT`, `*_SUCCESS_THRESHOLD`
- **Metrics**: `METRICS_PORT` (default 9095), Redis idempotency TTL settings

## 9. Resilience & Observability
### 9.1. Circuit Breaker Protection
- **Kafka Publishing**: `ResilientKafkaPublisher` with circuit breaker delegation
- **Configuration**: Failure threshold, recovery timeout, success threshold
- **Fallback**: Failed messages queued for retry when circuit opens
- **Metrics**: Circuit breaker state changes and call results

### 9.2. Metrics & Tracing
- **Prometheus**: `CollectorRegistry` injected via DI, exposed on `/metrics`
- **Core Counters**: Processed messages, LLM calls, callback latency, workflow duration, circuit breaker metrics
- **Batch Metrics**: Batch state distribution, progress percentages, stuck batch detection
- **Callback Metrics**: Processing latency, success/error rates, batch completion times
- **OpenTelemetry**: Full span creation and trace context propagation
- **Logging**: `huleedu_service_libs.logging_utils` with `correlation_id` extra, idempotency tracking

## 10. Security & Limits (Walking Skeleton)
- No auth; internal service only.
- DB credentials via env vars; no secrets in repo.
- Rate limit for LLM calls via semaphore-based concurrency control.
- Batch monitoring with automatic recovery for stuck batches.
- Future: OAuth for external API, essay text PII scrubbing.

## 11. Deployment
- **Docker**: `python:3.11-slim`, multi-stage.
- **Entrypoint**: `app.py` (unified Quart application with integrated Kafka consumer)
- **Commands**: `pdm run start` for production, `pdm run dev` for development
- **Ports**: 9095 (metrics/health), no external HTTP API.
- **Lifecycle**: Service manages both HTTP API and Kafka consumer in single process

## 12. Limitations & Future Work
- Current DB schema minimal; migrate to dedicated migrations tool (e.g., Alembic).
- Ranking stability threshold heuristic to be tuned (`SCORE_STABILITY_THRESHOLD`).
- LLM provider selection static; future: dynamic provider fail-over.

---

**CRITICAL IMPLEMENTATION NOTES**
- **DI Container**: Must be created *before* Blueprint registration in `app.py`
- **Idempotency**: Redis-based with 24-hour TTL using deterministic event IDs
- **Callback Processing**: Event-driven via Kafka, no polling. Callbacks linked via `request_correlation_id`
- **State Management**: Persistent batch state with optimistic locking for concurrent callback processing
- **Batch Monitoring**: Background task detects stuck batches (> 4 hours idle), auto-recovers or fails
- **Circuit Breaker**: Optional but recommended for Kafka publishing resilience
- **UUID Serialization**: Use `json.dumps(envelope.model_dump(mode="json"))` for proper UUID encoding
- **Testing**: Mock protocols, not implementations; expect UUID objects in correlation IDs