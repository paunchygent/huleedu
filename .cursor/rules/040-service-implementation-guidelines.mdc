---
description: Read before all work on web framework, I/O, API etc
globs: 
alwaysApply: false
---
# 040: Service Implementation Guidelines

## 1. Core Stack
- **Framework**: Quart for async HTTP services, direct `asyncio` and `aiokafka` for worker services.
- **Dependencies**: PDM exclusively (`pyproject.toml`, `pdm.lock`)
- **Programming**: `async/await` for all I/O operations

## 2. Async Patterns & Structure

### 2.1. Dependency Contracts & Protocols
- **MUST** define internal behavioral contracts using `typing.Protocol` in a `<service_name>/protocols.py` file.
- Business logic components (e.g., in `event_router.py` or Quart route handlers) **MUST** depend on these protocols, not concrete implementations directly.
- Concrete implementations of protocols are provided at the service entry point (e.g., in `worker_main.py` or `app.py`), ideally via a DI framework like Dishka.

### 2.2. Dependency Injection with Dishka
- **MUST** use Dishka DI framework for all services
- **HTTP Services**: Use `quart-dishka` integration with `@inject` decorator and `FromDishka[T]` annotations
- **Worker Services**: Use Dishka container with manual scoping for Kafka message processing

#### HTTP Service Pattern (Quart + quart-dishka):
```python
# app.py
from dishka import make_async_container
from quart_dishka import QuartDishka, inject
from di import ServiceProvider

@app.before_serving
async def startup():
    container = make_async_container(ServiceProvider())
    QuartDishka(app=app, container=container)

@app.post("/endpoint")
@inject
async def handler(dependency: FromDishka[Protocol]) -> Response:
    # Use dependency directly
    pass
```

#### Worker Service Pattern:
```python
# worker_main.py
from dishka import make_async_container

async def main():
    container = make_async_container(ServiceProvider())
    async with container() as request_container:
        dependency = await request_container.get(Protocol)
        # Use dependency
```

#### DI Provider Pattern:
- **MUST** create `<service>/di.py` with service-specific `Provider` class
- **MUST** use `@provide` decorator with appropriate scopes (`Scope.APP`, `Scope.REQUEST`)
- **MUST** return protocol interfaces, not concrete classes from business logic
```python
# di.py
from dishka import Provider, Scope, provide

class ServiceProvider(Provider):
    @provide(scope=Scope.APP)
    def provide_protocol(self) -> ProtocolInterface:
        return ConcreteImplementation()
```

### 2.3. Worker Service Structure Pattern (Example: Spell Checker)
- **`worker_main.py`**: Handles service lifecycle (startup, shutdown), Kafka client management, signal handling, and the primary message consumption loop. Initializes/injects dependencies.
- **`event_router.py`**: Contains logic for deserializing messages, implementing defined protocols (often by composing functions from `core_logic.py`), and orchestrating the processing flow for a single message.
- **`core_logic.py`**: Houses fundamental, reusable business logic, algorithms, and direct interactions with external systems (e.g., HTTP calls), implemented as standalone functions or simple classes.
- **`protocols.py`**: Defines `typing.Protocol` interfaces.

### 2.4. Resource Management (e.g., Kafka Clients, HTTP Sessions)
- **MUST** use `asynccontextmanager` for managing resources that require explicit setup and teardown (e.g., Kafka clients, `aiohttp.ClientSession`).
```python
@asynccontextmanager
async def managed_http_session() -> AsyncIterator[aiohttp.ClientSession]:
    async with aiohttp.ClientSession() as session:
        yield session

@asynccontextmanager
async def kafka_clients(
    # ... kafka config args ...
) -> AsyncIterator[tuple[AIOKafkaConsumer, AIOKafkaProducer]]:
    consumer = AIOKafkaConsumer(...)
    producer = AIOKafkaProducer(...)
    await consumer.start()
    await producer.start()
    try:
        yield consumer, producer
    finally:
        await consumer.stop()
        await producer.stop()
```

## 3. State Management
- Each service owns its primary entities' state
- State changes **MUST** be communicated via events
- Follow state transition logic from Architectural Design Blueprint

## 4. API Design
- RESTful principles
- Pydantic models for request/response schemas
- API versioning (`/v1/...`)
- `ErrorInfoModel` for standardized error responses

## 5. Configuration Management

### 5.1. Standardized Pydantic Settings Pattern
- **MUST** use `pydantic-settings` for all service configuration
- **MUST** create `config.py` at service root with this pattern:

```python
from __future__ import annotations
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    """Configuration settings for the [Service Name]."""
    LOG_LEVEL: str = "INFO"
    # Add typed fields with defaults
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="ignore",
        env_prefix="[SERVICE_NAME]_",
    )

settings = Settings()
```

### 5.2. Configuration Usage
- Import settings: `from .config import settings`
- Use `settings.FIELD_NAME` instead of `os.getenv()`
- Sensitive info **MUST NEVER** be hardcoded

## 6. Logging

### 6.1. Centralized Logging Utility
- **MUST** use `huleedu_service_libs.logging_utils` for all logging
- **FORBIDDEN**: Standard library `logging` module in services
- **Pattern**:
```python
from huleedu_service_libs.logging_utils import configure_service_logging, create_service_logger

# Service initialization
configure_service_logging("service-name", log_level=settings.LOG_LEVEL)
logger = create_service_logger("component-name")
```

### 6.2. Mandatory Correlation IDs
- For any operation chain (request/event), a `correlation_id` **MUST** be established or propagated
- This `correlation_id` **MUST** be in all log messages across all involved services
- Use `log_event_processing()` for EventEnvelope processing

### 6.3. Consistent Log Levels & Clear Messages
- Use appropriate levels (`DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`)
- Log messages **MUST** be clear, concise, and contextual
