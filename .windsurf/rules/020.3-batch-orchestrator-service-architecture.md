---
description: Batch Orchestrator Service (BOS) - Central workflow engine for essay batch processing with dynamic pipeline orchestration
alwaysApply: false
---
# 020.3: Batch Orchestrator Service Architecture

## Core Purpose
Central orchestrator for essay batch processing workflows using dynamic pipeline resolution and protocol-based clean architecture.

## Key Architectural Patterns

### 1. Dynamic Pipeline Orchestration
- **Phase Initiator Map**: `dict[PhaseName, PipelinePhaseInitiatorProtocol]` enables type-safe dynamic dispatch
- **Pipeline Resolution**: Uses BCS (Batch Conductor Service) to resolve user-requested pipelines into executable phase sequences
- **State Machine**: Each phase transitions through `PipelineExecutionStatus` with atomic repository updates

### 2. Clean Architecture Implementation
```
services/batch_orchestrator_service/
├── api/batch_routes.py           # Thin HTTP adapters (delegates to service layer)
├── implementations/              # Protocol implementations
│   ├── pipeline_phase_coordinator_impl.py  # Core orchestration logic
│   ├── batch_processing_service_impl.py    # Business logic layer
│   └── [phase_initiators]/       # Phase-specific initiators
├── protocols.py                  # Behavioral contracts (typing.Protocol)
└── di.py                        # Dishka provider configuration
```

### 3. Service Layer Pattern
- **BatchProcessingServiceImpl**: Centralized business logic for batch operations
- **PipelinePhaseCoordinator**: Orchestrates phase transitions and external service coordination
- **Repository Abstraction**: All data access through `BatchRepositoryProtocol`

## API Design Patterns

### External APIs
- **POST /v1/batches/register**: Lean registration with deferred context resolution
- **GET /v1/batches/{batch_id}/status**: Pipeline state queries
- **POST /v1/batches/{batch_id}/retry**: Phase retry with user validation

### Internal APIs
- **GET /internal/v1/batches/{batch_id}/pipeline-state**: Authoritative state for other services

## Event Architecture

### Publishing Events
- `huleedu.batch.essays.registered.v1`: Batch creation with internal essay IDs
- `huleedu.batch.service.student.matching.initiate.command.v1`: Phase 1 student matching command
- `huleedu.els.[phase].initiate.command.v1`: Phase 2+ commands to Essay Lifecycle Service

### Consumption Events
- `huleedu.batch.content.provisioning.completed.v1`: Content ready for batch type decision
- `huleedu.student.associations.confirmed.v1`: Phase 1 student associations confirmed
- `huleedu.els.batch.essays.ready.v1`: Batch ready for pipeline processing
- `huleedu.bos.client.pipeline.request.v1`: Client pipeline requests

## Phase 1 Student Matching Architecture

### Batch Type Decision Logic
```python
# Content provisioning triggers batch type decision
if batch_context.class_id:
    # REGULAR batch: initiate student matching
    await transition_to_awaiting_student_validation()
    await initiate_student_matching()
else:
    # GUEST batch: skip to ready state
    await transition_to_ready_for_pipeline_execution()
```

### State Transitions
- `AWAITING_CONTENT_VALIDATION` → `AWAITING_STUDENT_VALIDATION` (REGULAR)
- `AWAITING_CONTENT_VALIDATION` → `READY_FOR_PIPELINE_EXECUTION` (GUEST)
- `AWAITING_STUDENT_VALIDATION` → `STUDENT_VALIDATION_COMPLETED` (associations confirmed)
- `STUDENT_VALIDATION_COMPLETED` → `READY_FOR_PIPELINE_EXECUTION` (essays stored)

### Key Handlers
- `BatchContentProvisioningCompletedHandler`: Batch type decision and routing
- `StudentAssociationsConfirmedHandler`: Phase 1 completion handling

## Critical Implementation Patterns

### 1. Phase Initiation Protocol
```python
# Standardized interface for all phase initiators
async def initiate_phase(
    batch_id: str,
    phase_to_initiate: PhaseName,
    correlation_id: UUID,
    essays_for_processing: list[EssayProcessingInputRefV1],
    batch_context: BatchRegistrationRequestV1,
) -> None
```

### 2. Atomic State Management
- **Repository Responsibility**: All state transitions must be atomic
- **Expected Status Pattern**: Updates only proceed if current status matches expected
- **Race Condition Prevention**: Use compare-and-set or optimistic locking

### 3. Dynamic Dispatch Pattern
```python
# Phase initiators map enables generic orchestration
phase_initiators_map: dict[PhaseName, PipelinePhaseInitiatorProtocol] = {
    PhaseName.SPELLCHECK: spellcheck_initiator,
    PhaseName.CJ_ASSESSMENT: cj_assessment_initiator,
    # Additional phases added without coordinator changes
}
```

## Service Integration Patterns

### 1. Batch Conductor Service Integration
- **Pipeline Resolution**: HTTP API resolves user requests into executable phase sequences
- **Context Enrichment**: Provides educational context (teacher names, class info)

### 2. Essay Lifecycle Service Coordination
- **Command Pattern**: Initiates processing via Kafka commands
- **State Synchronization**: Maintains authoritative pipeline state
- **Result Aggregation**: Collects processing results for batch completion

## Production Critical Requirements

### 1. Atomic Operations (MANDATORY)
- **State Transitions**: All pipeline state changes must be atomic
- **Implementation**: Repository layer must prevent duplicate phase initiations
- **Testing**: Mock repositories must simulate production atomicity

### 2. Idempotency
- **Event Processing**: Redis-based idempotency keys
- **Phase Initiation**: Safe for multiple triggers/retries
- **State Updates**: Atomic compare-and-set operations

### 3. Error Boundaries
- **Phase Failures**: Isolated to specific phases, doesn't halt entire pipeline
- **Retry Logic**: Configurable retry strategies per phase type
- **Compensation**: Clear failure handling for partial pipeline completion

## Design Decisions

### 1. Lean Registration Pattern
- **Initial Storage**: Minimal batch data only
- **Context Resolution**: Educational context resolved during processing via Class Management Service
- **Benefit**: Reduces coupling, single source of truth for educational data

### 2. Internal Essay ID Generation
- **Authoritative IDs**: Service generates UUIDs for all essays in batch
- **Consistency**: Eliminates dependency on external ID formats
- **Traceability**: Clear lineage from batch to individual essay processing

### 3. Pipeline State as Single Source of Truth
- **Centralized State**: BOS maintains authoritative pipeline state
- **Service Coordination**: Other services query BOS for state information
- **UI Updates**: Real-time Redis notifications for frontend synchronization
