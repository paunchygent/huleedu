---
id: bff-vue-3-frontend-integration-design
title: Designing a BFF Layer for Vue 3 Frontend Integration
type: doc
status: research
priority: high
domain: frontend
service: ""
owner_team: frontend
owner: ""
program: ""
created: 2025-11-24
last_updated: 2025-11-24
related: []
labels: []
---
 
# Designing a BFF Layer for Vue 3 Frontend Integration
 
Implementing a Backend-for-Frontend (BFF) layer will bridge the event-driven microservices backend with the Vue 3 frontend. Below we detail the optimal BFF architecture and patterns for our scenario, addressing five key design decisions. This design builds on our existing infrastructure (API Gateway, WebSocket service, OpenAPI specs, etc.) and defines how per-role BFF services will provide tailored APIs to the Vue app.
1. BFF Service Topology and Structure
Separate BFF per User Role vs Single Multi-Role: We recommend separate BFF services for each role (e.g. bff-teacher and bff-admin), rather than one combined BFF. This follows microservice principles by keeping clear domain boundaries per role[1]. Each BFF can be owned and scaled independently, which is important since teacher-facing and admin-facing needs differ (teacher BFF will handle more screens and likely more load than the admin BFF). A future student-facing BFF can be added similarly when needed[2].
Service Responsibilities: - bff-teacher: Handles teacher UI needs (initially 4 screens: class dashboard, batch detail, essay feedback, student associations). It will compose data from services like Class Management (CMS), Result Aggregator (RAS), File/Content services, Identity, etc., focusing on what a teacher needs to see[3]. - bff-admin: Handles admin UI needs (initially 2 screens: user approval queue and system settings). It will interface with Identity service for account approvals and a new Config service for settings once that exists[3].
By separating these, each BFF stays small and focused. The code structure for each will mirror our existing service pattern[4]: - A lightweight FastAPI app (app.py) with common middlewares (CORS, auth, tracing). - Routes under a clear prefix [e.g. /v1/teacher/* in teacher routes module](5). - DTO models for responses (discussed below). - HTTP client modules for calling backend microservices (e.g. clients/cms_client.py, ras_client.py). - Optionally, a streaming component (e.g. Kafka/Redis listener) for pushing events (for real-time updates).
API Gateway Integration: The existing API Gateway will route external requests to the appropriate BFF: - Requests to /bff/v1/teacher/**-> forward to the teacher BFF service - Requests to /bff/v1/admin/** -> forward to the admin BFF service
This gateway mapping will be configured so that clients still have one entry point[6]. The gateway also continues to handle cross-cutting concerns (JWT validation, rate limiting, CORS) before requests reach the BFF. In Docker Compose, we’ll add the BFF services (each on its own internal port) and update the gateway’s routing config to point to them[7]. For example, bff-teacher might run on an internal URL like http://bff_teacher_service:8000 with gateway forwarding requests accordingly.
Each BFF will have its own environment configuration (set in Compose/Env files): - URLs for downstream services it needs [e.g. CMS_BASE_URL, RAS_BASE_URL, etc.](8). - Possibly an internal API key or token to authenticate itself to internal services. For instance, RAS’s internal endpoints might require an X-API-Key header that the BFF provides[8]. This ensures only authorized internal clients (like our BFFs) can call internal APIs.
Why not a single BFF? A combined BFF would mix teacher and admin logic, which complicates ownership and could introduce security risks (we’d need to carefully separate role-based access within one codebase). Separate services keep things cleaner: e.g. the teacher BFF can be deployed or updated independently of the admin BFF, and each can have its own scaling policy [teacher BFF might need more replicas if it’s heavily used](1).
2. Screen-Specific DTO Contract Design
Each frontend screen will communicate with the backend via a dedicated BFF endpoint that returns a screen-specific DTO (Data Transfer Object). Designing these DTOs is crucial, as they form the contract between the BFF and the Vue frontend.
Identifying Screen DTOs: For the Teacher role, we have four main screens and thus four read-model DTOs to define[9]: - Class Dashboard DTO – e.g. TeacherClassDashboardV1: Aggregated overview of all class batches for the teacher. Likely includes a list of batch summaries (batch ID, class, status, progress metrics, etc.) possibly grouped by class. Data sources: needs input from RAS (to get batch statuses for that teacher) and CMS [to list classes or attach class names](10). - Batch Detail DTO – e.g. TeacherBatchDetailV1: Detailed info for a specific batch. Contains batch metadata and the status of each essay in that batch [e.g. essay IDs, filenames, processing status, scores, etc.](11). Data sources: primarily RAS (which can provide a batch status with embedded essay statuses), plus possibly File Service for any file-specific info. We will compose these into one JSON for the frontend. - Essay Feedback DTO – e.g. TeacherEssayFeedbackV1: Data needed to render the essay grading/feedback screen. This likely overlaps with batch detail (one essay's details), but could include additional fields like the full essay text or AI feedback details. Data sources: could be retrieved by filtering the batch detail data for one essay, though ideally we add a direct endpoint. [We may extend RAS with GET /essays/{id} so the BFF doesn’t have to fetch the whole batch just for one essay](12). - Student Associations DTO – e.g. StudentAssociationListV1: Data for the “student-class associations” management screen, showing which students are associated with a batch and class, etc. Data source: the Class Management Service (CMS) already provides endpoints for getting and confirming associations[13]. The BFF will basically proxy or slightly transform those into the shape needed by the UI. There may also be a corresponding request DTO [e.g. AssociationConfirmRequestV1 for posting an association confirmation](13).
For the Admin role, initial screens and DTOs include: - Pending Users DTO – list of users awaiting approval (e.g. AdminPendingUsersV1), containing user info and any metadata needed for the admin to decide. Source: Identity Service [we need to implement endpoints like /users/pending and approval actions, as these are missing](14). - System Settings DTO – e.g. AdminSettingsV1, representing configurable system settings. Source: a new Config Service (to be created) or similar source[15].
DTO Definition and Ownership: We will define these DTOs within their respective BFF service codebases. Each BFF will have a dto/ module, e.g. services/bff_teacher_service/dto/teacher_v1.py, containing Pydantic models for that BFF’s responses[16]. By co-locating DTO models in the BFF, we ensure each BFF is the single source of truth for its API contract (no ambiguous shared models that could be used incorrectly elsewhere). This also makes versioning straightforward: the BFF can evolve its DTOs independently. For example, TeacherBatchDetailV1 is defined in bff-teacher – if we later need to change it in a backward-incompatible way, we could introduce TeacherBatchDetailV2 in the same BFF without affecting the admin BFF.
Versioning Strategy: We will use semantic versioning in both the URL and model names: - The API routes themselves include a version (e.g. /bff/v1/teacher/...). This v1 in the path signals the version of the contract[6]. Any breaking change to the contract would entail bumping this to v2 and maintaining the old v1 endpoints for backward compatibility if needed. - The Pydantic model classes will carry version suffixes [e.g. ...DashboardV1](17). This makes it clear which version of the response is being used in code, and allows parallel support of v1 and v2 if we ever had to (for example, if the frontend and BFF are deployed independently). - Non-breaking additions (like adding an optional field) can be done within v1 without changes to the URL, as JSON clients will ignore unknown fields. Breaking changes (removing or renaming fields, changing semantics) trigger a new version.
OpenAPI and TypeScript Integration: Once we implement these endpoints and DTOs in FastAPI, they will be automatically documented via OpenAPI. We already have a pipeline to generate TypeScript types from OpenAPI specs – this will include the new BFF DTO models (just as it currently includes our existing domain service models). Therefore, the Vue 3 frontend will get strongly-typed interfaces for each BFF response for free. This is a big win for developer productivity and catching integration issues early.
Composition Depth (Calls per Endpoint): Each BFF endpoint will aggregate data from one or more backend services. We should design the DTOs to include exactly the data each screen needs – no more, no less – even if that means the BFF must call multiple services: - Our goal is to minimize the number of calls per request (both for performance and simplicity). Ideally, some screens can be served with a single call to a specialized backend aggregator. For instance, to build the Teacher Dashboard DTO, we might call a RAS endpoint like GET /internal/v1/batches/user/{user_id} which returns all batch statuses for that teacher[18]. If we also need class names from CMS, that could be a second call to GET /v1/classes (filtered by teacher) and then we join the data. - Where possible, leverage the Result Aggregator Service (RAS) as it’s meant to provide query-optimized, aggregated data. The BFF should act mostly as a thin composition layer. E.g. for batch detail: RAS already gives a batch status with all essay statuses, so bff-teacher can mostly forward that (perhaps adding a bit of formatting or additional fields) rather than querying each domain service for essays[11]. If RAS lacks an endpoint we need (like fetching a single essay’s details), we have two choices: either call a broader endpoint and filter in the BFF, or extend RAS. In fact, adding an RAS endpoint (e.g. GET /internal/v1/essays/{id}) to avoid over-fetching an entire batch was noted as a desirable enhancement[12]. - Parallel calls: In cases where multiple sources are needed, the BFF can perform calls in parallel (since it’s I/O-bound). Using httpx.AsyncClient, for example, we can concurrently fetch data from CMS and RAS, then combine. This keeps latency closer to the slowest single call rather than sum of all. - Each BFF route will include the composition logic, but we should keep it clean. For clarity, consider offloading some logic to the client wrappers. For example, a method RASClient.get_batches_for_user(user_id) encapsulates calling RAS and returning a structured result, and CMSClient.get_classes_for_user(user_id) calls CMS. The route handler then just orchestrates these and maps into the DTO.
Example – Teacher Batch Detail Composition: The GET /v1/teacher/batches/{batch_id} endpoint in bff-teacher might: 1. Call RAS: /internal/v1/batches/{batch_id}/status to get overall batch info and essay list [if RAS provides essay details](19). 2. Possibly call File or Content service if we need extra info like file download links or full text for an essay (depending on UI needs). 3. Merge results into a TeacherBatchDetailV1 object and return. That DTO would include fields like batch_id, overall_status, created_at, last_updated, requested_pipeline (from RAS) and an array of essays each with their id, filename, and status details [spellcheck status, score, etc.](20).
Frontend State Integration: We design DTOs to be convenient for the Vue frontend. That means structuring data in a way that mirrors the UI components’ needs to minimize transformation on the client. For example, the Teacher Dashboard DTO might return an array of batch summaries already sorted/grouped as the UI needs, rather than making the frontend assemble that. We will document these contracts clearly so frontend can use them directly.
On the frontend: - Use TanStack Query (via Vue Query) to fetch these BFF endpoints. Each screen’s component (or a corresponding composable) will call the appropriate endpoint and get a typed DTO object. Because the DTOs are tailored, the component can directly bind to fields (e.g. iterate over dashboard.batches list, show batch.status etc.). - The Pinia store isn’t needed to hold these screen-specific lists long-term (Query will cache them), but Pinia can hold global state and context. For example, Pinia can keep the current user’s info (role, id, etc.) and perhaps some UI state, while Query manages server data state. Pinia could also manage something like a WebSocket connection (more on that in section 4). - One integration consideration: if our DTOs have certain computed fields or need client-side augmentation, we might ship minimal raw data and let the front-end compute some things. But since we control both sides, it's often simpler to compute everything server-side. The BFF can use common libraries or logic from common_core to populate fields. For instance, mapping internal status codes to human-readable statuses is already done in API Gateway for consistency[21][22]; BFF can follow the same patterns so the frontend gets user-friendly values.
DTO Versioning and Evolution: We will treat the BFF-to-frontend DTOs as versioned APIs. As noted, any breaking change (like changing a field name) will result in a new version path (/v2/...) and model class. This provides stability for the frontend. In practice, since our frontend and BFF are developed in tandem for this project, we may upgrade both together; but maintaining the discipline of versioning ensures future clients (or even third-party consumers if any) won’t be surprised by silent changes. We will also create contract tests to validate that the DTOs conform to expectations [for example, using example payloads](23), and possibly write OpenAPI-based tests to ensure the TS types match the Python models.
3. Backend-to-BFF Communication Patterns
This section covers how the BFF services will interact with the existing backend services, including how requests flow, how we handle auth, and error mapping.
Request Flow via API Gateway: In production, the client will call the API Gateway, which then routes to the BFF. The gateway already runs on port 4001 and performs JWT authentication and rate limiting[24][25]. We’ll extend it to forward /bff/v1/... paths to the BFFs (likely via environment config or a routing table). From the client’s perspective, calling GET /bff/v1/teacher/dashboard (for example) is just like any other API call. The gateway will validate the JWT, attach any necessary headers (like correlation IDs), then proxy the request to the teacher BFF service. The response flows back through the gateway (unchanged) to the client.
Note: In dev environments, we may allow the Vue app to call BFF directly (bypassing gateway) for simplicity, but then the BFF must handle CORS and JWT verification itself. This is doable (FastAPI + our libs can validate tokens), but using the gateway even in dev might be simpler if CORS is configured (the gateway’s CORS config can include the Vue dev server origins[26]). Either approach works, but the production pattern is always through the gateway.
Internal Service Calls (BFF -> Microservices): Once a request reaches the BFF, it will typically need to call one or more internal services (CMS, RAS, Identity, etc.) to gather data: - The BFF will use internal HTTP client libraries (we have some in libs/huleedu_service_libs and libs/common_core) or simple httpx calls. We’ll configure base URLs for each downstream service (e.g. environment variables like CMS_SERVICE_URL, RAS_SERVICE_URL) so the BFF knows where to send requests[27]. - Authentication/Authorization on Internal Calls: Our internal services are generally not exposed publicly and expect requests either from the gateway or other services. There are a few patterns: - Some services (like CMS, File Service, etc.) might accept the user’s JWT forwarded by an internal call. However, it’s more common in our architecture to rely on internal trust and service-level auth. For instance, the API Gateway currently proxies all /v1/classes/*calls directly to CMS with the user’s auth header passed through[28]. We could mimic that: the BFF could include the Authorization: Bearer <JWT> header when calling an internal service, effectively letting the internal service re-verify the token and enforce permissions. But this means duplicating JWT validation in each service. - An alternative is to use internal API keys or tokens. The BFF, being an internal client, might call an internal-only endpoint that’s not exposed to external users. For example, RAS has /internal/v1/batches/user/{id}[18] which likely requires an internal credential (as it’s not meant for direct external use). We’ll supply an API key (configured via env) in a header that RAS trusts (e.g., X-Internal-API-Key: <secret>). This way, RAS knows the request is from a trusted component. In such cases, the BFF must also include the target user’s ID in the request (either in the URL or as a header) so RAS knows whose data to fetch. - For services that don’t have a concept of internal vs external API (like CMS might treat all as external calls), the BFF can just forward the JWT. Since the gateway already validated it, it should still be valid. CMS can decode it to get user info if needed (or we modify CMS to trust an X-User-Id header from internal calls). - We will likely adopt a mix: use internal endpoints with service authentication whenever possible for efficiency and clarity. The BFF will extract the user’s ID (and role) from the JWT (the gateway can pass this via headers or the BFF can decode the JWT again using our common JWT library) and use that to call internal APIs. For example, call CMS GET /v1/classes?owner_id={teacher_id} (once that exists) to get the teacher’s classes[29], or call RAS internal endpoint for that user’s batches[18]. - Propagation of Correlation IDs: We have correlation ID support across services for tracing. The gateway likely generates a X-Correlation-ID for each request (or uses one from the client) and passes it on. The BFF should ensure to pass that along to all internal calls, so that in logs we can trace a single client request through BFF into underlying services. Our service libs support grabbing the correlation context and injecting it into outbound calls.
Using the Result Aggregator vs Direct Composition: One major design question is how “smart” the BFF should be. Our approach: - Prefer leveraging backend aggregation for complex data whenever available. The Result Aggregator Service (RAS) was built to provide read-optimized views (it listens to events from many services and maintains queryable models). For use cases like “get all batches for a user with their statuses and maybe some summary info”, RAS is ideal – one call gives the data[10]. The BFF can then lightly transform that into a DTO (or even pass it through largely unchanged if it matches what the UI needs). - For data that spans services where no single service pre-aggregates it, the BFF will do on-demand composition by calling multiple services. For example, the Teacher Dashboard might need class info from CMS plus batch info from RAS. Until RAS maybe includes class names in its output, the BFF will call both and join. This is okay because it’s still limited in scope (just 2 calls). - If we find the BFF would need to orchestrate too many calls (e.g., call 5 different microservices for one screen), that’s a signal to either refactor the backend (perhaps have RAS or a new aggregator handle that scenario) or introduce caching (see section 5) or even consider denormalizing data. In our current screens, it looks manageable: the worst case might be 2-3 calls for a screen. For instance, Essay Feedback screen might need RAS for the essay’s analysis results and maybe Content Service for the essay text if not stored in RAS. - We will implement missing backend endpoints to simplify BFF logic wherever reasonable. The plan already notes adding a CMS endpoint to list classes by teacher[29] and a RAS endpoint to fetch a single essay’s info[29]. These will prevent the BFF from doing filtering or making extra round-trips to fetch related data.
Error Handling and Mapping: It is vital that BFF services present errors to the frontend in a consistent, user-friendly way. We will adopt the same structured error format used elsewhere in our platform: - Our common error handling library (in huleedu_service_libs) provides FastAPI exception handlers that produce a JSON error envelope with fields like error_code, message, and correlation_id[30][31]. We will register these handlers in each BFF service so that any HuleEduError we raise will be serialized automatically in this format[32]. - Mapping internal errors: When calling backend services, the BFF should catch failures and map them to appropriate error codes for the client. For example: - A 404 from RAS (batch not found) -> BFF raises HuleEduError(ErrorCode.RESOURCE_NOT_FOUND, "Batch not found", ...) so that the frontend gets { "error_code": "RESOURCE_NOT_FOUND", "message": "Batch not found", ... }. - A validation issue (e.g. bad request parameters) -> raise VALIDATION_ERROR with details. - If a downstream service is down or returns 500, BFF can return an EXTERNAL_SERVICE_ERROR or a generic SERVER_ERROR with a message like "Service unavailable, please try later". The correlation_id would let us trace which service failed. - Authentication issues should be caught at the gateway (if JWT is invalid/expired, gateway returns 401). But if for some reason an unauthorized call reaches BFF, we can also return 401/403 appropriately (probably using AUTHENTICATION_ERROR or AUTHORIZATION_ERROR codes). - Consistency with Gateway: The API Gateway already produces errors in this format [with base error codes like VALIDATION_ERROR, AUTHENTICATION_ERROR, etc.](33)[31]. Our BFF will use the same base ErrorCode enum from common_core to ensure we don’t introduce new, inconsistent codes for the frontend. (For example, both gateway and BFF will use RESOURCE_NOT_FOUND rather than one using NOT_FOUND and the other RESOURCE_MISSING or something.) - Correlation IDs: The BFF should log a correlation ID for each request (likely provided by gateway via header, or generated if not present) and include it in any error responses[34]. This helps both in debugging (frontend can report an error with its correlation_id, and we can find it in logs) and in linking logs across the gateway, BFF, and services.
End-to-End Request Example: Teacher Batch Detail request – The Vue app calls /bff/v1/teacher/batches/123: 1. Gateway: verifies JWT, sees path /bff/v1/teacher/* and routes to bff-teacher. 2. BFF-Teacher: receives request, extracts user ID (from JWT or header) and batch_id=123. Calls RAS: GET /internal/v1/batches/123/status?user_id={teacherId} (assuming RAS needs user for auth or filtering). RAS returns batch status JSON (or an error). - If RAS 404s (batch not found or not owned by that user), BFF catches that and raises a RESOURCE_NOT_FOUND error which becomes a 404 to client[31]. - If RAS is slow or unreachable, BFF times out (after a configured timeout, e.g., 3 seconds) and raises an EXTERNAL_SERVICE_ERROR with message like "Batch service unavailable". - Assuming success, BFF now maybe calls no other service (if RAS gave all essay details needed). It maps the RAS response into our TeacherBatchDetailV1 Pydantic model. This could involve renaming some fields or combining data (e.g., RAS might give raw status codes that BFF maps to user-friendly status text). 3. BFF returns the DTO as JSON. FastAPI (with Pydantic) will ensure it’s proper JSON per the model. 4. Gateway: simply forwards this JSON back to client. (Since the gateway is likely acting as a reverse proxy for this path, it might not even “know” the contents; it just streams the response.) 5. Frontend: receives the JSON and, if using Vue Query, normalizes it into the component state via the typed DTO.
This pattern holds for other endpoints, with the variations of how many internal calls and any special logic per case.
4. Real-Time Updates and Vue Integration Patterns
Real-time notifications will ensure the Vue UI stays in sync with backend events (e.g. batch progress, completions) without manual refresh. We already have a WebSocket service set up for pushing events to clients, so here we define how the BFF, WebSocket, and Vue frontend coordinate.
WebSocket Service & Notification Channels: Our WebSocket service (FastAPI-based) is deployed and uses Redis Pub/Sub to broadcast messages to clients[35]. Clients connect to it via ws://.../ with a JWT token query param for auth. Internally, the WebSocket service subscribes to Redis channels like user:{user_id}:events and when a message is published on such a channel, it forwards it to the corresponding connected user. We have ~15 notification event types defined in the system (e.g., batch status updated, essay scored, etc.).
BFF’s Role in Publishing Events: The BFF services will be the logical producers of certain high-level events relevant to the frontend: - When a teacher performs an action or requests data that can change, our backend microservices will usually emit events to Kafka (since the system is event-driven). The Result Aggregator (RAS) picks those up and updates its read models. But to push to the UI in real-time, something needs to emit to WebSocket/Redis. - We have two options: either individual services (or RAS) publish directly to Redis on state changes, or the BFF layer does it. Given that BFF is assembling the data, a sensible approach is for BFF to publish “view-model” events: small JSON payloads that match or correlate with its DTOs. - For the initial implementation, we can have the teacher BFF subscribe to relevant domain events (likely via Kafka or an event bus) for the teacher’s domain. For example, if there is a “BatchProgressUpdated” event from the processing pipeline, the BFF (or even RAS) could catch it. The BFF can then publish a refined event to Redis channel user:{teacher_id}:events containing just what the UI needs to know [e.g., batch 123 status changed to “completed”](36). - The BFF might include a small module (streaming/ in the service structure) to handle this: perhaps a Kafka consumer listening to certain topics and a Redis client to publish events[37]. - Alternatively, RAS could do the publishing when it updates a batch’s status. But having the BFF do it allows customizing the payload specifically for the frontend. - We will start with streaming for Teacher Dashboard and Batch Detail screens as these benefit the most from live updates[38]. For example: - Dashboard updates: when any batch visible on the teacher’s dashboard changes status (or a new batch is added), send an event. Payload might be { "event": "BATCH_UPDATED", "batch_id": 123, "new_status": "completed_successfully", "progress": 100 }. The UI can use this to update the status and progress bar for that batch in real-time. - Batch detail updates: when an essay within a batch gets a new score or finishes processing, if the teacher is viewing that batch, they should see the change. A payload might be { "event": "ESSAY_UPDATED", "batch_id": 123, "essay_id": 456, "new_score": 4.5, "status": "graded" }. The UI could update the specific essay’s row in the detail view. - Admin screens may have less real-time need, but possibly for user approvals (if one admin approves a user, other admins should see that update). Initially, we can skip WebSocket for admin until needed, focusing on teacher.
Payload Strategy – Deltas vs Full Refresh: We will favor sending minimal diffs (deltas) over full data snapshots[36]. Each WebSocket event will carry just enough info for the client to update its state: - This reduces bandwidth and avoids issues with large payloads. For example, not re-sending the entire list of batches when only one batch changed. - It does put some onus on the client to merge the update, but that’s manageable with a good state management approach (see below). - In some cases, a delta might just be a trigger to refetch data. For instance, if a change is complex, the event could simply say “X changed” and the frontend could then invalidate a query to fetch a fresh copy of the data from the BFF. But since our BFF is already getting events, it’s often easy to include some details in the event. - Example: When a batch completes, the BFF might publish {event: "BATCH_COMPLETED", batch_id: 123, overall_status: "completed_successfully", completed_at: "...timestamp..."}. The frontend uses this to instantly update the status of batch 123 to “Completed” in all relevant views. If the UI wants more info (like a final score summary), it might still call the BFF for full detail, or we include those in the event if trivial.
Vue Frontend Integration: - We will implement a WebSocket client in the Vue 3 app that connects to our WebSocket service. This can be done via the browser WebSocket API. The connection URL will include the JWT token (e.g. ws://<host>/?token=<JWT> as our service expects[39]). - It's wise to encapsulate this in a Vue composable or Pinia store. For example, we might create a Pinia store called useRealtimeStore or a composable useWebSocket(): - This module handles opening the WebSocket connection when the user is authenticated and the app is ready. It will also handle reconnection logic: if the socket closes unexpectedly, attempt to reconnect after a delay (exponential backoff up to a limit). In the Svelte integration, they implemented up to 5 reconnection attempts[40]; we can do something similar in Vue (perhaps using a simple counter and setTimeout). - It should manage a reactive connection state (e.g. isConnected boolean, maybe an error message if failed). - It will listen for incoming messages (ws.onmessage) and parse the event data (JSON). - For distributing events to the parts of the app that care, there are a few patterns: - Pinia store for notifications: The WebSocket store could keep a reactive list/queue of incoming notifications. E.g. notifications = ref([]) where each incoming event object is pushed onto this array. Components can then watch this array for changes. However, we likely don’t want to accumulate all events (could grow indefinitely). Instead, we might process and apply them on the fly. - Directly update relevant state: If the event corresponds to data we have in a Pinia store or a Vue Query cache, we update that. For instance, suppose we have a Pinia store holding the teacher’s batch list, we could directly mutate the appropriate batch entry when a BATCH_UPDATED event comes. This was the approach in the Svelte example: they had an effect that listened to a notifications store and updated the batches store accordingly[41]. In Vue, we can achieve similar reactivity with watchers or computed values tied to a Pinia store. - Integration with TanStack Query: Since we plan to use Vue Query for data fetching, we can integrate events by invalidating or updating query results: - Invalidation: On a relevant event, call queryClient.invalidateQueries(['teacherDashboard']) (for example) to refetch the latest data for that query. This ensures the UI gets updated data, though it introduces a slight delay (the network round-trip) and load on BFF. Still, it’s a straightforward way to reconcile state after a disconnect or when changes are complex. - Direct cache update: Alternatively, use queryClient.setQueryData to directly merge the new info into the cached data. For example, on BATCH_UPDATED, we can update the cached list of batches in the dashboard query without refetching. TanStack Query’s reactive data will then cause UI to update immediately. This is more efficient and instant. We’d do something like:
queryClient.setQueryData(['teacherDashboard'], (currentData) => {
  if (!currentData) return currentData;
  return {
    ...currentData,
    batches: currentData.batches.map(batch =>
      batch.id === event.batch_id 
        ? { ...batch, status: event.new_status, progress: event.progress } 
        : batch
    )
  };
});
This uses the event payload to patch the state. We need to ensure the event has enough info (status, progress, etc.) to do this. - For the batch detail query, similarly, update the specific essay in the cached data on an ESSAY_UPDATED event. - Using query cache updates keeps a single source of truth (the Query cache) rather than duplicating state in Pinia. It’s a clean approach given our heavy use of Query for server state. - We can use a combination: quick local cache updates for simple stuff and fallback to invalidation for anything complex or if an event indicates a major change (like new data added). - Reconnection and State Sync: When the WebSocket reconnects after a dropout, there is a chance we missed some events while disconnected. Our strategy: - On reconnect, the client can automatically trigger a refresh of certain queries. For instance, if the app was on the dashboard, we call invalidateQueries(['teacherDashboard']) so it fetches the latest state from the BFF (which is eventually consistent via RAS). Similarly, if on a batch detail page, refetch that batch’s data. This ensures we catch up with any missed updates. - We should handle the scenario of the user being offline or the WS being down gracefully – maybe show an indicator “Live update disconnected” after X failed attempts so they know data might be stale. - The reconnection backoff can start at a couple of seconds and double up to, say, 30 seconds. If after a certain number of tries it fails, we might stop trying or switch to a different approach (in practice, WebSocket service availability issues should be rare if the backend is up). - Vue Composable/Store Implementation: To outline, we might do something like:
// useWebSocket.ts (composable or within a Pinia store)
const WS_URL = import.meta.env.VITE_WS_BASE_URL;
let socket: WebSocket | null = null;
const isConnected = ref(false);
const notifications = ref([] as Array<any>);
const reconnectAttempts = ref(0);

function connectWS(token: string) {
  socket = new WebSocket(`${WS_URL}?token=${token}`);
  socket.onopen = () => { 
    isConnected.value = true; 
    reconnectAttempts.value = 0;
  };
  socket.onmessage = (event) => {
    const data = JSON.parse(event.data);
    notifications.value.push(data);
    handleEvent(data);
  };
  socket.onclose = () => {
    isConnected.value = false;
    socket = null;
    if (reconnectAttempts.value < 5) {
      const timeout = 1000 * 2 ** reconnectAttempts.value;
      reconnectAttempts.value += 1;
      setTimeout(() => connectWS(token), timeout);
    } else {
      console.warn("WebSocket: Max reconnection attempts reached");
    }
  };
}
Here, handleEvent(data) would contain the logic to update queries or Pinia stores based on event type. We likely don’t actually need to keep all events in notifications array; we could process and drop them. In Svelte they used an array and $effect to react to it[42], but in Vue we could just call our update functions directly in onmessage as above. - Which components subscribe: If using a global WebSocket store, we might just initiate the connection once when the app loads (after login). Alternatively, we only connect when a user navigates to a part of the app that needs real-time data. Simpler is to connect after login and stay connected while the user is using the app, so they can receive notifications anywhere (we can always ignore events not relevant to the current view, or even show a toast if something happened off-screen). - Security: The JWT query param ensures only authenticated users receive their own events. The WebSocket service presumably validates the token and knows the user ID from it to subscribe to user:{id}:events channel. We must ensure to refresh the token if it expires or handle reconnect with a new token after a re-login if needed. (For a long-lived single page app, if JWTs expire often, we might need a refresh mechanism – but that’s more on auth side.)
By implementing this real-time channel: - Teachers will see changes live: e.g., as essays are graded in the background, the progress bars and status indicators update automatically, and when all are done a “Complete” status appears without reload. This greatly enhances UX for an event-driven system. - Admins might later get live notifications (e.g., a new user registered could trigger an update on the pending-users screen if open, or a badge increment if not currently viewing that screen).
5. Caching and Performance Strategy
Efficient data retrieval is key for a snappy UI and to avoid overwhelming backend services. We’ll employ caching at multiple levels, carefully considering consistency.
Client-Side Caching (Vue Query): The first line of caching is in the browser: - TanStack Query will, by default, cache query results for a certain time (often 5 minutes by default, configurable). This means if a teacher navigates away from a page and back, or performs refetches within that window, the data can be served from cache instantly. We will tune the cache times per query – for example, the teacher dashboard data might be set to stale after, say, 30 seconds or 1 minute, since it’s moderately dynamic. Admin settings data could be cached longer as it changes rarely. - Vue Query also batches and de-duplicates requests: if two components ask for the same data at the same time, it will only fetch once. This prevents redundant calls to BFF for the same resource. - The presence of real-time updates means in many cases the UI will get notified of changes rather than polling. This allows us to use long cache stale times for things like the dashboard list, because we don’t need to re-poll frequently – events will prompt updates. We can set the queries to stale maybe after several minutes and rely on events for interim consistency, effectively treating the WebSocket as an active cache invalidation mechanism.
BFF Layer Caching: On the server side, the BFF can optionally implement caching of the aggregated results it computes: - We are considering short TTL caches within the BFF services for expensive or frequently accessed data[43]. For instance, if the teacher dashboard endpoint is hit very often (say the user refreshes or multiple components request it), having the BFF store the last result for that user for, e.g., 10-30 seconds can significantly cut down repeated work. - BFF caching could be in-memory (simple Python dict or an LRU cache) or distributed (using Redis). Trade-offs: - In-memory: very fast, but each instance of the BFF will have its own cache. In a scaled-out scenario, user might bounce between instances and miss cache hits. Also memory is per-instance. - Redis: a single cache store all instances consult. This adds a network hop and serialization overhead, but ensures consistency and sharing. We already have Redis available (used by WebSocket and rate limiting). - Given initial scope, we can start with in-memory caching for simplicity, and if we see the need (or if running multiple replicas behind a load balancer), we can switch to Redis-backed caching fairly easily (our common_core or service libs might even have a helper for caching with Redis). - Cache what? Likely cache the final DTO response (or a close approximation) keyed by parameters. For example, cache the result of get_dashboard(user_id) so that if within 30 seconds the same user requests it again, we serve from cache instead of hitting RAS and CMS again. Similarly, get_batch_detail(user_id, batch_id) could be cached per batch for a short time. - We should not cache real-time changing data for too long. A short TTL (seconds to a minute) is important so the UI doesn’t get stale data. Moreover, our WebSocket events can help us invalidate caches: - If a BATCH_UPDATED event comes in for batch 123, the teacher BFF (if it is aware of it) could drop or update the cache entry for batch_id=123 and for the dashboard list that contains that batch. This way, subsequent requests get fresh data. - We can integrate cache invalidation with our event-consumer in BFF. E.g., when BFF publishes an event to the user’s WS channel, it can also clear the corresponding cache (since it knows that data changed). - Cache for static/reference data: Some data is relatively static or expensive to fetch repeatedly. Example: a list of all classes a teacher has – if that doesn’t change often (only when new class is created or teacher assigned), caching it for say 5 minutes or more is fine. Another example might be system config for admin, or a list of options that rarely change. We can afford longer TTL there, or even cache indefinitely until an admin changes a setting. Invalidation can be triggered by the admin change action in that case. - We will use cache aside pattern: check cache first, if miss, fetch from source and populate cache. Ensure to handle cache errors gracefully (if Redis is down, just fetch normally and serve). Also, avoid caching error responses.
Performance Considerations: - Caching helps with read performance, but we also ensure each call is efficient: - Use asynchronous I/O in BFF so that calls to other services don’t block the event loop. This way one BFF instance can serve many concurrent requests. - Enable gzip compression on responses (FastAPI can do this), especially for potentially large DTOs (like a dashboard listing dozens of batches). - Use pagination on any large lists if needed in DTOs (for now our lists are manageable, but if a teacher had hundreds of batches, we might introduce pagination or lazy loading in the UI). - Circuit Breakers and Timeouts: As part of resilience (and related to caching), we configure timeouts for each backend call (for example, if RAS doesn’t respond in 2 seconds, timeout). If a particular service is consistently failing or slow, a circuit breaker could temporarily stop calls to it and either use cached data or return an error quickly. Our service libs mention resilience features [like an inbuilt circuit breaker pattern](44)[45]. We will incorporate those to avoid cascading failures. For instance, if RAS is down, the BFF might immediately return a cached last-known dashboard data with a flag “stale” or an error telling the user some data is temporarily unavailable, rather than hang. - Cache consistency: Because of the event-driven nature, our data in backend is eventually consistent. A cache could serve slightly outdated info (e.g., a batch just finished but cache still has it as running). Our multi-layer approach mitigates this: - The WebSocket event would notify the UI of the finish possibly before the user even triggers a refresh. But if they did refresh right at that moment, the cache might give old data. However, since the BFF also got the event (and ideally cleared cache), this window is small. - We accept minor staleness in favor of performance, as long as we correct it via events or periodic refresh. - In worst case, the TTL ensures the cache clears soon anyway.
Client vs Server Cache: We should also consider whether to rely more on client caching (which is easier to manage per-user and doesn’t risk stale data across users) versus server caching (which can reduce load on backends for common queries): - Many BFF queries are per-user (teacher’s own data), which means one user’s cache doesn’t help another. Client-side cache is naturally per-user, so it’s very effective. Server-side caching per user can help if the user is making rapid repeated calls (or if the UI inadvertently calls the same endpoint twice). It won’t help with multi-user scenarios since each has different data. So server cache benefit is somewhat limited to the same user hitting the same endpoint frequently. - However, some data might overlap users or not depend on user. For example, if the admin settings DTO is same for all admins, that could be cached globally. Or if we had public/reference data (not much in this context). - Given that, our focus will be on client caching and optimization first, and we will add server caching for specific cases where we identify bottlenecks or redundant calls (e.g., if a teacher’s dashboard is requested very often in short bursts). - We’ll also instruct the frontend team to use features like "background refetching" and not to spam requests. The combination of Query and real-time updates should actually reduce the need for manual refresh.
In summary, the caching strategy is to use short-lived caches to absorb transient repeated requests and to leverage the event system for cache invalidation. Our design explicitly notes this trade-off and will be revisited as usage patterns emerge[43].
Additional Vue Integration Notes
While not part of the BFF architecture per se, aligning on frontend patterns will ensure a smooth end-to-end implementation:
• State Management Choices: We confirm the plan to use Pinia and TanStack Vue Query together:
• Use Pinia for global application state – e.g. current user info, auth token (if not in cookie), UI preferences, and possibly to manage the WebSocket connection status as discussed. Pinia is great for reactive global stores and is much simpler than Vuex was.
• Use Vue Query for server-derived state – all data that comes from APIs (our BFF endpoints). This library will handle caching, loading states, and syncing with devtools, etc. This separation means we don't manually manage loading/error for every API call; we leverage Query's hooks.
• Pinia and Query can work together: e.g., the auth Pinia store could provide the JWT token that Query uses in its fetcher for authenticated calls. And Query's results can be fed into Pinia if we want to store some of it globally (though generally we can keep it in components).
• Composition API & Code Organization: We will use the Vue 3 Composition API throughout, as it's recommended for TypeScript and code reuse. Instead of large option-api components, we'll factor logic into composables (in src/composables/ or alongside feature components):
• e.g., a useTeacherDashboardData() composable might internally use useQuery(['teacherDashboard'], fetchDashboard) to get data and return { data, error, isLoading } to the component. This keeps the component code clean.
• Similarly, useBatchDetail(batchId) uses a query to fetch that batch’s detail.
• WebSocket integration can be a composable or part of a global Pinia store as described.
• This approach mirrors the modular backend (each BFF endpoint has a corresponding front-end hook).
• Project Structure: We favor a feature-based structure for front-end files. For instance:
    src/
  modules/
    teacher/
      DashboardView.vue
      useDashboardData.ts
      BatchDetailView.vue
      useBatchDetail.ts
      ...
    admin/
      PendingUsersView.vue
      usePendingUsers.ts
      ...
  store/
    auth.ts
    websocket.ts (if using Pinia for WS)
  App.vue, main.ts, etc.
    Grouping by feature (teacher vs admin, or even specific screens) makes it easier to develop and maintain, as each feature might have its own routes, state, and composables. It also aligns with our backend separation (we can have separate sections in docs or code for teacher vs admin features).
• Example Frontend Workflow: Once the BFF’s OpenAPI is published, the frontend team will generate TS types. They create a Pinia store for auth, and perhaps a plugin to inject an axios or fetch wrapper that attaches the JWT token. They set up Vue Query's client. For a Teacher Dashboard page, they use our TeacherClassDashboardV1 type from the types file and write:
    const { data: dashboard, error, isLoading } = useQuery(['teacherDashboard'], () =>
  fetch('/bff/v1/teacher/dashboard').then(res => res.json()) 
);
    The UI can then bind dashboard.value.batches to render a list. When the WebSocket pushes an update, we handle it by updating this cache as discussed.
• Pinia for UI State: Pinia might hold things like a loading spinner state or selected items, but those are minor. It can also hold a small number of persistent notifications or modals, etc., which is outside our scope here.
• Authentication Flow: It’s worth noting the JWT auth flow remains standard – the user logs in (likely via the Identity service through the gateway), gets a token, and the frontend stores it (likely in memory or localStorage for dev, and using secure cookies in production as mentioned in integration guide). The BFF uses that JWT for identifying the user (via gateway). Nothing special needed here beyond what’s done.
By establishing these patterns, both backend and frontend teams have a clear contract and roadmap. To recap the benefits: - Each role-focused BFF cleanly encapsulates business logic for that UI, simplifying both ends of development[1]. - Screen-specific DTOs mean the frontend doesn’t have to stitch data from multiple endpoints, and changes to data needs are easy to track [one DTO per screen](23). - The API gateway and auth infrastructure ensure security and consistency across all calls [no bypassing authentication, uniform error handling](31). - Real-time via WebSockets provides a responsive UX, and our design of diff-based events plus cache invalidation strikes a balance between immediacy and correctness[36]. - Caching strategies at multiple layers will improve performance while minimizing stale data risk[43]. - Using modern Vue 3 patterns (Composition API, Pinia, Vue Query) will make the frontend highly maintainable and scalable, which complements the scalable backend architecture.
This design, once approved, unblocks the next steps: - Backend team: Can start implementing the Teacher BFF service (skeleton, endpoints, integration with existing services) as outlined in the plan[46], followed by Admin BFF once teacher flows are validated. - Frontend team: Can proceed setting up the Vue 3 project structure with Pinia and Query, and begin building pages using the agreed DTO contracts (even using mock data until the BFF is live, since we have the OpenAPI and can create sample JSON). They now know how state will be managed and how real-time updates will come in. - DevOps: Will add the new BFF services to Docker Compose and adjust API Gateway config to route /bff/v1/teacher and /bff/v1/admin prefixes to the correct containers[7]. Also ensure the WebSocket service CORS and origins include the new frontend origin [already handled in dev config for Vite](26), and that appropriate environment variables (service URLs, API keys, JWT secret references) are set for the BFF containers.
By adhering to this architecture, we create a clear Backend-for-Frontend layer that cleanly separates frontend-specific needs from the core microservices, accelerating development and reducing complexity on both sides. The design is flexible enough to accommodate future features (e.g., adding a Student BFF later, or expanding teacher/admin functionality) without breaking existing contracts.
 
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [23] [29] [30] [35] [36] [37] [38] [39] [43] [46] bff-pattern-adoption-and-rollout-plan.md
<https://github.com/paunchygent/huledu-reboot/blob/061ca5b1c4bf23a6bf9a448708c9c1e436469ecf/TASKS/architecture/bff-pattern-adoption-and-rollout-plan.md>
[21] [22] [24] [25] [27] [28] [31] [32] [33] [34] README.md
<https://github.com/paunchygent/huledu-reboot/blob/061ca5b1c4bf23a6bf9a448708c9c1e436469ecf/services/api_gateway_service/README.md>
[26] svelte5-cors-and-dev-utilities.md
<https://github.com/paunchygent/huledu-reboot/blob/061ca5b1c4bf23a6bf9a448708c9c1e436469ecf/TASKS/frontend/svelte5-cors-and-dev-utilities.md>
[40] [41] [42] SVELTE_INTEGRATION_GUIDE.md
<https://github.com/paunchygent/huledu-reboot/blob/061ca5b1c4bf23a6bf9a448708c9c1e436469ecf/docs/how-to/SVELTE_INTEGRATION_GUIDE.md>
[44] [45] README.md
<https://github.com/paunchygent/huledu-reboot/blob/061ca5b1c4bf23a6bf9a448708c9c1e436469ecf/libs/huleedu_service_libs/README.md>
