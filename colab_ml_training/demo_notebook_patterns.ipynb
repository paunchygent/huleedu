{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Hybrid Notebook Development Patterns Demo\n",
    "\n",
    "This notebook demonstrates the core patterns for developing notebooks that run successfully in both **VS Code (Local)** and **Google Colab / Containers**.\n",
    "\n",
    "**Core Constraints:**\n",
    "1.  **Environment Agnosticism**: Paths must be dynamic.\n",
    "2.  **Secret Management**: Secrets must be loaded robustly or injected.\n",
    "3.  **Dependencies**: Must be installed in the active kernel.\n",
    "4.  **Process Management**: Clean up background processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATTERN 1: Dependency Management\n",
    "# --------------------------------\n",
    "# PROBLEM: The notebook kernel is isolated from your host's 'pdm' environment.\n",
    "# SOLUTION: Use %pip install within the notebook.\n",
    "\n",
    "%pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATTERN 2: Filesystem Isolation (The \"Container Gap\")\n",
    "# -----------------------------------------------------\n",
    "# PROBLEM: In Colab/Containers, hardcoded paths like '/Users/name/...' do not exist.\n",
    "# SOLUTION: Use dynamic paths relative to Path.cwd().\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Dynamic root detection\n",
    "CURRENT_DIR = Path.cwd()\n",
    "print(f\"Current Working Directory: {CURRENT_DIR}\")\n",
    "\n",
    "# Create a dummy file in the current environment\n",
    "DATA_FILE = CURRENT_DIR / \"demo_data.txt\"\n",
    "DATA_FILE.write_text(\"This file was created dynamically!\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ Wrote file to: {DATA_FILE}\")\n",
    "print(f\"   Exists? {DATA_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8da748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clear any stale keys from the current kernel session so PATTERN 3 will re-load/prompt.\n",
    "os.environ.pop(\"OPENAI_API_KEY\", None)\n",
    "os.environ.pop(\"LLM_PROVIDER_SERVICE_OPENAI_API_KEY\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATTERN 3: Secret Management with Fallback\n",
    "# ------------------------------------------\n",
    "# PROBLEM: Host .env files are not automatically mounted in containers.\n",
    "# SOLUTION: Try to find .env, but allow manual injection or fallback.\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def load_secrets_robustly():\n",
    "    # 1. Search for .env dynamically (walking up directory tree)\n",
    "    current = Path.cwd()\n",
    "    env_path = None\n",
    "    for _ in range(5):\n",
    "        if (current / \".env\").exists():\n",
    "            env_path = current / \".env\"\n",
    "            break\n",
    "        if current.parent == current:\n",
    "            break\n",
    "        current = current.parent\n",
    "\n",
    "    if env_path:\n",
    "        print(f\"‚úÖ Found .env at: {env_path}\")\n",
    "        load_dotenv(env_path, override=True)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  .env not found (expected in container environments).\")\n",
    "\n",
    "    # 2. If running inside HuleEdu Docker, map the prefixed service key into\n",
    "    # OPENAI_API_KEY for this notebook kernel session.\n",
    "    prefixed_key = os.environ.get(\"LLM_PROVIDER_SERVICE_OPENAI_API_KEY\")\n",
    "    if prefixed_key and not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = prefixed_key\n",
    "\n",
    "    # 3. Prompt interactively as a last resort (no secrets committed)\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        api_key = getpass(\"Enter OPENAI_API_KEY (will not be echoed): \").strip()\n",
    "        if api_key:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    return api_key\n",
    "\n",
    "\n",
    "final_key = load_secrets_robustly()\n",
    "masked = f\"{final_key[:4]}...{final_key[-4:]}\" if final_key else \"None\"\n",
    "print(f\"Active OpenAI Key: {masked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATTERN 4: Execution Verification\n",
    "# -------------------------------\n",
    "# ACTION: Use the injected secret and installed dependency to prove connectivity.\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ùå No API key found. Skipping API call.\")\n",
    "else:\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "\n",
    "        print(\"ü§ñ Sending request to OpenAI (gpt-5-nano) [Attempt 3: Debugging empty response]...\")\n",
    "\n",
    "        # Using the requested Nano model with correct params\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-5-nano\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Say 'Nu f√∂rst√•r du hur du ska anv√§nda\"\n",
    "                    \"Jupyter notebooks in VS Code!' in German.\",\n",
    "                }\n",
    "            ],\n",
    "            max_completion_tokens=2000,\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "        print(f\"‚úÖ Response Content: '{content}'\")\n",
    "\n",
    "        # Debug: Print full details if content is empty\n",
    "        if not content:\n",
    "            print(\"\\n‚ö†Ô∏è Content was empty! Full response debug:\")\n",
    "            print(response.model_dump_json(indent=2))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API Call Failed: {e}\")\n",
    "        print(\"Note: If you see 'max_tokens' error, try reloading the notebook window.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
