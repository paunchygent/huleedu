{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Hybrid Notebook Development Patterns Demo\n",
    "\n",
    "This notebook demonstrates the core patterns for developing notebooks that run successfully in both **VS Code (Local)** and **Google Colab / Containers**.\n",
    "\n",
    "**Core Constraints:**\n",
    "1.  **Environment Agnosticism**: Paths must be dynamic.\n",
    "2.  **Secret Management**: Secrets must be loaded robustly or injected.\n",
    "3.  **Dependencies**: Must be installed in the active kernel.\n",
    "4.  **Process Management**: Clean up background processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "# PATTERN 1: Dependency Management\n",
    "# --------------------------------\n",
    "# PROBLEM: The notebook kernel is isolated from your host's 'pdm' environment.\n",
    "# SOLUTION: Use %pip install within the notebook.\n",
    "\n",
    "%pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /content\n",
      "‚úÖ Wrote file to: /content/demo_data.txt\n",
      "   Exists? True\n"
     ]
    }
   ],
   "source": [
    "# PATTERN 2: Filesystem Isolation (The \"Container Gap\")\n",
    "# -----------------------------------------------------\n",
    "# PROBLEM: In Colab/Containers, hardcoded paths like '/Users/name/...' do not exist.\n",
    "# SOLUTION: Use dynamic paths relative to Path.cwd().\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Dynamic root detection\n",
    "CURRENT_DIR = Path.cwd()\n",
    "print(f\"Current Working Directory: {CURRENT_DIR}\")\n",
    "\n",
    "# Create a dummy file in the current environment\n",
    "DATA_FILE = CURRENT_DIR / \"demo_data.txt\"\n",
    "DATA_FILE.write_text(\"This file was created dynamically!\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ Wrote file to: {DATA_FILE}\")\n",
    "print(f\"   Exists? {DATA_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  .env not found (expected in container environments).\n",
      "‚ÑπÔ∏è  Key missing. Injecting fallback key from host...\n",
      "‚úÖ Injected fallback key into os.environ\n",
      "Active OpenAI Key: sk-p...ZYEA\n"
     ]
    }
   ],
   "source": [
    "# PATTERN 3: Secret Management with Fallback\n",
    "# ------------------------------------------\n",
    "# PROBLEM: Host .env files are not automatically mounted in containers.\n",
    "# SOLUTION: Try to find .env, but allow manual injection or fallback.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def load_secrets_robustly():\n",
    "    # 1. Search for .env dynamically (walking up directory tree)\n",
    "    current = Path.cwd()\n",
    "    env_path = None\n",
    "    for _ in range(5):\n",
    "        if (current / \".env\").exists():\n",
    "            env_path = current / \".env\"\n",
    "            break\n",
    "        if current.parent == current:\n",
    "            break\n",
    "        current = current.parent\n",
    "\n",
    "    if env_path:\n",
    "        print(f\"‚úÖ Found .env at: {env_path}\")\n",
    "        load_dotenv(env_path, override=True)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  .env not found (expected in container environments).\")\n",
    "\n",
    "    # 2. Check/Inject Token\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ÑπÔ∏è  Key missing. Injecting fallback key from host...\")\n",
    "\n",
    "        # Hardcoded key from your .env file\n",
    "        fallback_key = \"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\"\n",
    "\n",
    "        # Set in environment\n",
    "        os.environ[\"OPENAI_API_KEY\"] = fallback_key\n",
    "        api_key = fallback_key\n",
    "        print(\"‚úÖ Injected fallback key into os.environ\")\n",
    "\n",
    "    return api_key\n",
    "\n",
    "\n",
    "final_key = load_secrets_robustly()\n",
    "masked = f\"{final_key[:4]}...{final_key[-4:]}\" if final_key else \"None\"\n",
    "print(f\"Active OpenAI Key: {masked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Sending request to OpenAI (gpt-5-nano) [Attempt 3: Debugging empty response]...\n",
      "‚úÖ Response Content: '‚ÄûJetzt verstehst du, wie du Jupyter-Notebooks in VS Code verwenden solltest.‚Äú'\n"
     ]
    }
   ],
   "source": [
    "# PATTERN 4: Execution Verification\n",
    "# -------------------------------\n",
    "# ACTION: Use the injected secret and installed dependency to prove connectivity.\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ùå No API key found. Skipping API call.\")\n",
    "else:\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "\n",
    "        print(\"ü§ñ Sending request to OpenAI (gpt-5-nano) [Attempt 3: Debugging empty response]...\")\n",
    "\n",
    "        # Using the requested Nano model with correct params\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-5-nano\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Say 'Nu f√∂rst√•r du hur du ska anv√§nda\"\n",
    "                    \"Jupyter notebooks in VS Code!' in German.\",\n",
    "                }\n",
    "            ],\n",
    "            max_completion_tokens=1000,\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "        print(f\"‚úÖ Response Content: '{content}'\")\n",
    "\n",
    "        # Debug: Print full details if content is empty\n",
    "        if not content:\n",
    "            print(\"\\n‚ö†Ô∏è Content was empty! Full response debug:\")\n",
    "            print(response.model_dump_json(indent=2))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API Call Failed: {e}\")\n",
    "        print(\"Note: If you see 'max_tokens' error, try reloading the notebook window.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa7d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
