# docker-compose.observability.yml
# HuleEdu Core Observability Stack: Prometheus, Loki, Grafana

volumes:
  prometheus_data: {}
  loki_data: {}
  grafana_data: {}
  alertmanager_data: {}
  jaeger_data: {}

# Networks are defined in the parent docker-compose.yml

services:
  prometheus:
    image: prom/prometheus:v2.53.0
    container_name: huleedu_prometheus
    restart: unless-stopped
    networks:
      - huleedu_internal_network
    ports:
      - "9091:9090"  # FIXED: Changed from 9092 to 9091 to avoid Kafka conflict
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: huleedu_alertmanager
    restart: unless-stopped
    depends_on:
      - prometheus
    networks:
      - huleedu_internal_network
    ports:
      - "9094:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/config.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9094'

  loki:
    image: grafana/loki:3.1.0
    container_name: huleedu_loki
    restart: unless-stopped
    networks:
      - huleedu_internal_network
    ports:
      - "3100:3100"
    volumes:
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    image: grafana/promtail:3.1.0
    container_name: huleedu_promtail
    restart: unless-stopped
    depends_on:
      - loki
    networks:
      - huleedu_internal_network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml

  jaeger:
    image: jaegertracing/all-in-one:1.50
    container_name: huleedu_jaeger
    restart: unless-stopped
    networks:
      - huleedu_internal_network
    ports:
      - "16686:16686"    # Jaeger UI
      - "4317:4317"      # OTLP gRPC receiver
      - "4318:4318"      # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=memory
      - MEMORY_MAX_TRACES=10000
    volumes:
      - jaeger_data:/tmp

  grafana:
    image: grafana/grafana:11.0.0
    container_name: huleedu_grafana
    restart: unless-stopped
    depends_on:
      - prometheus
      - loki
      - jaeger
    networks:
      - huleedu_internal_network
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_DATASOURCES_0_NAME=Prometheus
      - GF_DATASOURCES_0_TYPE=prometheus
      - GF_DATASOURCES_0_URL=http://prometheus:9090
      - GF_DATASOURCES_0_IS_DEFAULT=true
      - GF_DATASOURCES_1_NAME=Loki
      - GF_DATASOURCES_1_TYPE=loki
      - GF_DATASOURCES_1_URL=http://loki:3100

  # Infrastructure exporters for comprehensive monitoring
  kafka_exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: huleedu_kafka_exporter
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - huleedu_internal_network
    ports:
      - "9308:9308"
    command:
      - '--kafka.server=kafka:9092'
      - '--web.listen-address=0.0.0.0:9308'
      - '--log.level=info'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9308/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  postgres_exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: huleedu_postgres_exporter
    networks:
      - huleedu_internal_network
    ports:
      - "9187:9187"
    environment:
      # Primary database connection - monitors batch_orchestrator_db
      DATA_SOURCE_NAME: "postgresql://${HULEEDU_DB_USER}:${HULEEDU_DB_PASSWORD}@batch_orchestrator_db:5432/batch_orchestrator?sslmode=disable"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  redis_exporter:
    image: oliver006/redis_exporter:latest
    container_name: huleedu_redis_exporter
    networks:
      - huleedu_internal_network
    ports:
      - "9121:9121"
    environment:
      REDIS_ADDR: "redis://redis:6379"
    # Health check removed - the oliver006/redis_exporter image doesn't include wget/curl
    # and the exporter binary doesn't have a built-in health check mode.
    # Monitor via Prometheus scrape success metric instead.

  node_exporter:
    image: prom/node-exporter:latest
    container_name: huleedu_node_exporter
    networks:
      - huleedu_internal_network
    ports:
      - "9100:9100"
    command:
      - '--collector.disable-defaults'
      - '--collector.cpu'
      - '--collector.loadavg'
      - '--collector.meminfo'
    # Removed problematic volume mount for macOS compatibility
    # volumes:
    #   - '/:/host:ro,rslave'  # Not supported on macOS/Darwin
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s 