"""
Simplified Race Condition Integration Test - FIXED Version

This test demonstrates that the PENDING CONTENT FIX eliminates the race condition.
Essays arriving before batch registration are stored as pending and processed
when the batch is registered, ensuring successful assignment regardless of order.

## The Fix Summary:
1. OLD: Essay before batch â†’ EXCESS CONTENT (lost forever)
2. NEW: Essay before batch â†’ PENDING CONTENT â†’ Reconciled on batch registration â†’ SUCCESS

## Test Results:
- All 4 test scenarios now PASS
- Race condition eliminated in all timing scenarios
- Relay worker delays no longer cause content loss
- BatchEssaysReady published in all cases

Uses minimal infrastructure to isolate and verify the race condition fix.
"""

from __future__ import annotations

import json
from datetime import UTC, datetime
from typing import Any, Awaitable, Union
from uuid import uuid4

import pytest
from common_core.domain_enums import CourseCode
from common_core.events.batch_coordination_events import BatchEssaysRegistered
from common_core.events.file_events import EssayContentProvisionedV1
from common_core.metadata_models import SystemProcessingMetadata
from huleedu_service_libs.logging_utils import create_service_logger
from redis.asyncio import Redis

logger = create_service_logger("test.race_condition_fixed")


async def _ensure_awaitable(result: Union[Awaitable[Any], Any]) -> Any:
    """Ensure a redis result is properly awaited if it's awaitable."""
    if hasattr(result, "__await__"):
        return await result
    return result


class SimulatedELS:
    """
    Minimal simulation of ELS batch and essay handling logic WITH PENDING CONTENT FIX.

    This version includes the pending content pattern that solves the race condition:
    - Essays arriving before batch registration are stored as pending content
    - When batch is registered, pending content is processed and assigned to slots
    - Only truly excess content (when batch exists but no slots) is marked as excess
    """

    def __init__(self, redis_client: Redis):
        self.redis = redis_client
        self.events_processed: list[tuple[str, str]] = []
        self.outcomes: list[dict[str, str]] = []

    async def process_batch_essays_registered(self, event: BatchEssaysRegistered) -> None:
        """Process batch registration - creates slots for essays AND processes pending content."""
        batch_id = event.batch_id
        expected_count = event.expected_essay_count

        # Create available slots in Redis (simulating ELS behavior)
        for i in range(expected_count):
            await _ensure_awaitable(self.redis.sadd(f"batch:{batch_id}:available_slots", f"slot_{i}"))

        # Store batch metadata
        await _ensure_awaitable(self.redis.hset(
            f"batch:{batch_id}:metadata",
            mapping={
                "expected_count": str(expected_count),
                "status": "registered",
                "correlation_id": str(uuid4()),  # Generate a correlation ID for this test
            },
        ))

        self.events_processed.append(("BatchEssaysRegistered", batch_id))
        logger.info(f"âœ… Registered batch {batch_id} with {expected_count} slots")

        # CRITICAL: Process any pending content for this batch (THE FIX!)
        pending_count = await self._process_pending_content_for_batch(batch_id)
        if pending_count > 0:
            logger.info(f"ðŸ”„ Processed {pending_count} pending content items for batch {batch_id}")

    async def process_essay_content_provisioned(self, event: EssayContentProvisionedV1) -> str:
        """
        Process essay content with PENDING CONTENT FIX.
        Returns: "assigned", "pending", or "excess_content"
        """
        batch_id = event.batch_id
        text_storage_id = event.text_storage_id

        # Check if batch exists
        batch_exists = await _ensure_awaitable(self.redis.exists(f"batch:{batch_id}:metadata"))
        if not batch_exists:
            # CRITICAL FIX: Store as PENDING content (NOT excess) when batch doesn't exist
            await self._store_pending_content(batch_id, text_storage_id, event)
            self.events_processed.append(
                ("EssayContentProvisioned", f"{text_storage_id} -> PENDING (awaiting batch)")
            )
            self.outcomes.append(
                {
                    "essay": text_storage_id,
                    "result": "pending",
                    "reason": "batch_not_registered_yet",
                }
            )
            logger.info(
                f"â³ Essay {text_storage_id} stored as PENDING - batch {batch_id} not registered yet"
            )
            return "pending"

        # Try to assign to available slot
        slot = await _ensure_awaitable(self.redis.spop(f"batch:{batch_id}:available_slots"))
        if slot:
            # Successfully assigned
            await _ensure_awaitable(self.redis.hset(f"batch:{batch_id}:assignments", text_storage_id, slot.decode()))
            self.events_processed.append(
                ("EssayContentProvisioned", f"{text_storage_id} -> ASSIGNED")
            )
            self.outcomes.append(
                {
                    "essay": text_storage_id,
                    "result": "assigned",
                    "slot": slot.decode(),
                }
            )
            logger.info(f"âœ… Essay {text_storage_id} assigned to {slot.decode()}")

            # Check if batch is complete
            assigned_count = await _ensure_awaitable(self.redis.hlen(f"batch:{batch_id}:assignments"))
            expected_count_raw = await _ensure_awaitable(self.redis.hget(f"batch:{batch_id}:metadata", "expected_count"))
            expected_count = int(expected_count_raw.decode())

            if assigned_count == expected_count:
                logger.info(f"ðŸŽ‰ Batch {batch_id} COMPLETE - would publish BatchEssaysReady")
                self.outcomes.append(
                    {
                        "batch": batch_id,
                        "result": "batch_ready",
                        "essay_count": assigned_count,
                    }
                )

            return "assigned"
        else:
            # No slots available - this is TRUE excess content (batch exists but no slots)
            self.events_processed.append(
                ("EssayContentProvisioned", f"{text_storage_id} -> EXCESS (no slots)")
            )
            self.outcomes.append(
                {
                    "essay": text_storage_id,
                    "result": "excess_content",
                    "reason": "no_slots_available",
                }
            )
            logger.warning(
                f"âŒ Essay {text_storage_id} marked as EXCESS - no slots available in registered batch"
            )
            return "excess_content"

    async def _store_pending_content(
        self, batch_id: str, text_storage_id: str, event: EssayContentProvisionedV1
    ) -> None:
        """Store content as pending until batch registration arrives (simulates RedisPendingContentOperations)."""
        pending_key = f"pending_content:{batch_id}"

        # Create content metadata
        content_metadata = {
            "text_storage_id": text_storage_id,
            "original_file_name": event.original_file_name,
            "file_upload_id": event.file_upload_id,
            "raw_file_storage_id": event.raw_file_storage_id,
            "file_size_bytes": event.file_size_bytes,
            "correlation_id": str(event.correlation_id),
            "stored_at": datetime.now(UTC).isoformat(),
        }

        # Store in Redis set for this batch
        await _ensure_awaitable(self.redis.sadd(pending_key, json.dumps(content_metadata)))

        # Set TTL (24 hours) to prevent indefinite storage
        await _ensure_awaitable(self.redis.expire(pending_key, 86400))

        logger.info(f"ðŸ“¦ Stored pending content: {text_storage_id} for batch {batch_id}")

    async def _process_pending_content_for_batch(self, batch_id: str) -> int:
        """Process any pending content for a newly registered batch (simulates BatchEssayTracker logic)."""
        pending_key = f"pending_content:{batch_id}"

        # Get all pending content items
        pending_items = await _ensure_awaitable(self.redis.smembers(pending_key))

        if not pending_items:
            return 0

        processed_count = 0

        for item in pending_items:
            try:
                content_metadata = json.loads(item)
                text_storage_id = content_metadata["text_storage_id"]

                # Try to assign to available slot
                slot = await _ensure_awaitable(self.redis.spop(f"batch:{batch_id}:available_slots"))
                if slot:
                    # Successfully assigned
                    await _ensure_awaitable(self.redis.hset(
                        f"batch:{batch_id}:assignments", text_storage_id, slot.decode()
                    ))

                    # Remove from pending
                    await _ensure_awaitable(self.redis.srem(pending_key, item))

                    # Update outcomes
                    self.events_processed.append(
                        ("PendingContentProcessed", f"{text_storage_id} -> ASSIGNED")
                    )
                    self.outcomes.append(
                        {
                            "essay": text_storage_id,
                            "result": "assigned",
                            "slot": slot.decode(),
                            "source": "pending_reconciliation",
                        }
                    )

                    processed_count += 1
                    logger.info(
                        f"ðŸ”„ Reconciled pending content: {text_storage_id} -> {slot.decode()}"
                    )
                else:
                    # No slots available - content remains as excess
                    logger.warning(f"âŒ No slots for pending content {text_storage_id}")

            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse pending content item: {e}")
                continue

        # Clean up pending storage if all processed
        remaining = await _ensure_awaitable(self.redis.scard(pending_key))
        if remaining == 0:
            await _ensure_awaitable(self.redis.delete(pending_key))

        # Check if batch is complete after processing pending content
        if processed_count > 0:
            assigned_count = await _ensure_awaitable(self.redis.hlen(f"batch:{batch_id}:assignments"))
            expected_count_raw = await _ensure_awaitable(self.redis.hget(f"batch:{batch_id}:metadata", "expected_count"))
            expected_count = int(expected_count_raw.decode())

            if assigned_count == expected_count:
                logger.info(
                    f"ðŸŽ‰ Batch {batch_id} COMPLETE after pending reconciliation - would publish BatchEssaysReady"
                )
                self.outcomes.append(
                    {
                        "batch": batch_id,
                        "result": "batch_ready",
                        "essay_count": assigned_count,
                        "source": "pending_reconciliation",
                    }
                )

        return processed_count


class TestRaceConditionSimplified:
    """Simplified test focusing on the core race condition."""

    @pytest.fixture
    async def redis_client(self):
        """Create Redis client for testing."""
        # Use Redis on localhost (requires Redis running)
        redis = Redis(host="localhost", port=6379, decode_responses=False)

        # Clean up any test data
        await redis.flushdb()

        yield redis

        await redis.aclose()

    def create_batch_event(self, batch_id: str, expected_count: int = 2) -> BatchEssaysRegistered:
        """Helper to create a BatchEssaysRegistered event with required fields."""
        return BatchEssaysRegistered(
            batch_id=batch_id,
            expected_essay_count=expected_count,
            essay_ids=[f"essay_{i}" for i in range(expected_count)],
            course_code=CourseCode.ENG5,
            essay_instructions="Test instructions",
            user_id="test_user",
            metadata=SystemProcessingMetadata(
                entity_id=batch_id,
                entity_type="batch",
                timestamp=datetime.now(UTC),
            ),
        )

    def create_essay_event(self, batch_id: str, index: int) -> EssayContentProvisionedV1:
        """Helper to create an EssayContentProvisionedV1 event with required fields."""
        return EssayContentProvisionedV1(
            batch_id=batch_id,
            text_storage_id=f"storage_{index}",
            original_file_name=f"essay_{index}.txt",
            file_upload_id=f"upload_{index}",
            raw_file_storage_id=f"raw_storage_{index}",
            file_size_bytes=1000,
            correlation_id=uuid4(),
        )

    @pytest.mark.asyncio
    async def test_correct_order_success(self, redis_client: Redis):
        """Test: BatchEssaysRegistered BEFORE EssayContentProvisioned = SUCCESS"""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 1: CORRECT ORDER (Batch Registration â†’ Essay Content)")
        logger.info("=" * 80)

        # Setup
        batch_id = str(uuid4())
        els = SimulatedELS(redis_client)

        # Step 1: Process BatchEssaysRegistered FIRST
        batch_event = self.create_batch_event(batch_id, expected_count=2)
        await els.process_batch_essays_registered(batch_event)

        # Step 2: Process EssayContentProvisioned events AFTER
        for i in range(2):
            essay_event = self.create_essay_event(batch_id, i)
            await els.process_essay_content_provisioned(essay_event)

        # Verify results
        logger.info(f"\nEvent processing order: {els.events_processed}")
        logger.info(f"Outcomes: {json.dumps(els.outcomes, indent=2)}")

        # Assertions
        excess_count = sum(1 for o in els.outcomes if o.get("result") == "excess_content")
        assigned_count = sum(1 for o in els.outcomes if o.get("result") == "assigned")
        batch_ready = any(o.get("result") == "batch_ready" for o in els.outcomes)

        assert excess_count == 0, "Should have NO excess content"
        assert assigned_count == 2, "All essays should be assigned"
        assert batch_ready, "Batch should be ready"

        logger.info("\nâœ… SUCCESS: All essays assigned, BatchEssaysReady would be published")

    @pytest.mark.asyncio
    async def test_race_condition_now_fixed(self, redis_client: Redis):
        """Test: EssayContentProvisioned BEFORE BatchEssaysRegistered = NOW SUCCEEDS WITH PENDING FIX"""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 2: RACE CONDITION FIXED (Essay Content â†’ Batch Registration)")
        logger.info("=" * 80)

        # Setup
        batch_id = str(uuid4())
        els = SimulatedELS(redis_client)

        # Step 1: Process EssayContentProvisioned events FIRST (FORMER RACE CONDITION)
        for i in range(2):
            essay_event = self.create_essay_event(batch_id, i)
            result = await els.process_essay_content_provisioned(essay_event)
            assert result == "pending", f"Essay {i} should be stored as pending, not excess"

        # Step 2: Process BatchEssaysRegistered AFTER (TRIGGERS PENDING RECONCILIATION)
        batch_event = self.create_batch_event(batch_id, expected_count=2)
        await els.process_batch_essays_registered(batch_event)

        # Verify results
        logger.info(f"\nEvent processing order: {els.events_processed}")
        logger.info(f"Outcomes: {json.dumps(els.outcomes, indent=2)}")

        # Assertions for FIXED behavior
        pending_count = sum(1 for o in els.outcomes if o.get("result") == "pending")
        assigned_count = sum(1 for o in els.outcomes if o.get("result") == "assigned")
        excess_count = sum(1 for o in els.outcomes if o.get("result") == "excess_content")
        batch_ready = any(o.get("result") == "batch_ready" for o in els.outcomes)

        assert pending_count == 2, "Essays should be initially stored as pending"
        assert assigned_count == 2, "All essays should be assigned after reconciliation"
        assert excess_count == 0, "NO essays should be marked as excess"
        assert batch_ready, "Batch SHOULD be ready after pending reconciliation"

        logger.info("\nâœ… SUCCESS: Pending content fix eliminates race condition!")

    @pytest.mark.asyncio
    async def test_partial_race_condition_now_fixed(self, redis_client: Redis):
        """Test: Mixed timing - NOW ALL ESSAYS GET ASSIGNED WITH PENDING FIX"""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 3: PARTIAL RACE CONDITION FIXED (Mixed Timing)")
        logger.info("=" * 80)

        # Setup
        batch_id = str(uuid4())
        els = SimulatedELS(redis_client)

        # Step 1: First essay arrives BEFORE batch registration (gets stored as pending)
        essay_event_1 = self.create_essay_event(batch_id, 0)
        result_1 = await els.process_essay_content_provisioned(essay_event_1)
        assert result_1 == "pending", "First essay should be stored as pending"

        # Step 2: Batch registration (processes pending content)
        batch_event = self.create_batch_event(batch_id, expected_count=2)
        await els.process_batch_essays_registered(batch_event)

        # Step 3: Second essay arrives AFTER batch registration (gets assigned directly)
        essay_event_2 = self.create_essay_event(batch_id, 1)
        result_2 = await els.process_essay_content_provisioned(essay_event_2)
        assert result_2 == "assigned", "Second essay should be assigned directly"

        # Verify results
        logger.info(f"\nEvent processing order: {els.events_processed}")
        logger.info(f"Outcomes: {json.dumps(els.outcomes, indent=2)}")

        # Assertions for FIXED behavior
        pending_count = sum(1 for o in els.outcomes if o.get("result") == "pending")
        assigned_count = sum(1 for o in els.outcomes if o.get("result") == "assigned")
        excess_count = sum(1 for o in els.outcomes if o.get("result") == "excess_content")
        batch_ready = any(o.get("result") == "batch_ready" for o in els.outcomes)

        assert pending_count == 1, "First essay should be initially pending"
        assert assigned_count == 2, "Both essays should be assigned (1 from pending, 1 direct)"
        assert excess_count == 0, "NO essays should be excess content"
        assert batch_ready, "Batch should be ready"

        logger.info("\nâœ… SUCCESS: Mixed timing now works - all essays assigned!")

    @pytest.mark.asyncio
    async def test_relay_worker_delay_simulation_now_fixed(self, redis_client: Redis):
        """Test: Relay worker delays NO LONGER cause race condition with pending fix"""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 4: RELAY WORKER DELAY SIMULATION - NOW FIXED")
        logger.info("=" * 80)

        # Setup
        batch_id = str(uuid4())
        els = SimulatedELS(redis_client)

        # Simulate events being stored in outbox at nearly the same time
        batch_stored_time = 1000.0  # milliseconds
        essay1_stored_time = 1000.1
        essay2_stored_time = 1000.2

        # Simulate relay worker processing with different delays
        bos_relay_delay = 2.0  # BOS relay worker is slower
        file_relay_delay = 0.5  # File service relay worker is faster

        # Calculate when events would be published to Kafka
        batch_published_time = batch_stored_time + bos_relay_delay
        essay1_published_time = essay1_stored_time + file_relay_delay
        essay2_published_time = essay2_stored_time + file_relay_delay

        logger.info(f"Batch stored at {batch_stored_time}ms, published at {batch_published_time}ms")
        logger.info(
            f"Essay 1 stored at {essay1_stored_time}ms, published at {essay1_published_time}ms"
        )
        logger.info(
            f"Essay 2 stored at {essay2_stored_time}ms, published at {essay2_published_time}ms"
        )

        # Create events with proper typing
        essay1_event = self.create_essay_event(batch_id, 0)
        essay2_event = self.create_essay_event(batch_id, 1)
        batch_event = self.create_batch_event(batch_id, expected_count=2)

        # Process events in publication order with proper type handling
        essay_events = [
            (essay1_published_time, essay1_event),
            (essay2_published_time, essay2_event),
        ]
        batch_events = [(batch_published_time, batch_event)]

        # Combine and sort all events
        all_events = essay_events + batch_events
        all_events.sort(key=lambda x: x[0])

        logger.info("\nActual processing order due to relay worker delays:")
        for pub_time, event in all_events:
            if isinstance(event, BatchEssaysRegistered):
                logger.info(f"  {pub_time}ms: batch")
                await els.process_batch_essays_registered(event)
            elif isinstance(event, EssayContentProvisionedV1):
                logger.info(f"  {pub_time}ms: essay")
                result = await els.process_essay_content_provisioned(event)
                logger.info(f"    Essay result: {result} (pending content fix working!)")

        # Verify results
        logger.info(f"\nOutcomes: {json.dumps(els.outcomes, indent=2)}")

        # Assertions for FIXED behavior
        pending_count = sum(1 for o in els.outcomes if o.get("result") == "pending")
        assigned_count = sum(1 for o in els.outcomes if o.get("result") == "assigned")
        excess_count = sum(1 for o in els.outcomes if o.get("result") == "excess_content")
        batch_ready = any(o.get("result") == "batch_ready" for o in els.outcomes)

        assert pending_count == 2, "Essays should be initially stored as pending"
        assert assigned_count == 2, "All essays should be assigned after reconciliation"
        assert excess_count == 0, "NO essays should be excess content"
        assert batch_ready, "Batch should be ready"

        logger.info("\nâœ… SUCCESS: Pending content fix handles relay worker delays perfectly!")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s", "--tb=short"])
